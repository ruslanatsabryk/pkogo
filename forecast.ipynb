{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38e64d76-c788-4b3d-9eab-a19bc693668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit, OrthogonalMatchingPursuitCV\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a36d14-2f54-4edd-bd04-3ecba00281fe",
   "metadata": {},
   "source": [
    "#### Функция чтения набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dff2f17e-4fab-4bbe-9c1f-465b9638cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_river_dataset(fname, pr_list=None, y_name='H_max'):\n",
    "    pr_arr = []\n",
    "    y_arr = []\n",
    "    with open(fname, newline='') as f:\n",
    "        reader = csv.DictReader(f, delimiter=';')\n",
    "        for row in reader:\n",
    "            pr_arr_row = []\n",
    "            for pr in pr_list:\n",
    "                pr_arr_row.append(row[pr])\n",
    "\n",
    "            pr_arr.append(pr_arr_row)\n",
    "            y_arr.append(row[y_name])\n",
    "    X = np.asarray(pr_arr, dtype=np.float64)\n",
    "    y = np.asarray(y_arr, dtype=np.float64)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f85915-970a-4a02-b6e5-85aa86fa8e1d",
   "metadata": {},
   "source": [
    "#### Функция формирования тестового набора данных с подстановкой нормированных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "260024c9-0662-4996-8761-ea9bfe657cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_norm(x, pr_list, norms):\n",
    "    x_norm = np.copy(x)\n",
    "    for col, pr in enumerate(pr_list):\n",
    "        if pr in norms:\n",
    "            x_norm[:, col:col+1] = norms[pr]\n",
    "    return x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4310b5c9-b79e-427d-b7b4-68e70d34794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataset_csv(year, dataset, dataset_name, fieldnames, pr_group, mode='training'):\n",
    "    if mode == 'estimation':\n",
    "        dir_path = f'results/Estimation/{year}/{dataset_name}/group-{pr_group}/'\n",
    "        file_name = f'{dataset_name}-гр{pr_group}-Оценка.csv'\n",
    "    elif mode == 'training':\n",
    "        dir_path = f'results/Models/{year}/'\n",
    "        file_name = f'{dataset_name}-гр{pr_group}-Обучение.csv'\n",
    "    elif mode == 'forecast':\n",
    "        dir_path = f'results/Forecast/{year}/'\n",
    "        file_name = f'{dataset_name}-гр{pr_group}-Прогноз.csv'\n",
    "    else:\n",
    "        ...\n",
    "    \n",
    "    with open(\n",
    "        f'{dir_path}'\n",
    "        f'{file_name}', \n",
    "        'w', newline='', encoding='utf-8'\n",
    "    ) as csvfile:\n",
    "        \n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames, \n",
    "                                delimiter=';', extrasaction='ignore')\n",
    "        writer.writeheader()\n",
    "        writer.writerows(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafb25dc-b5b4-4ca1-a00c-1bf000b6e5bc",
   "metadata": {},
   "source": [
    "### Функция прогнозирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60d417d6-3c45-4804-b8b6-3ce9f89a3841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(year, norms=False):\n",
    "\n",
    "    fieldnames = [\n",
    "        'Predictors', \n",
    "        'Equations', \n",
    "        'Method', \n",
    "        'Criterion', \n",
    "        'Correlation', \n",
    "        'Pm',\n",
    "        'R2',        \n",
    "        'R2_t',\n",
    "        'Prediction',\n",
    "    ]\n",
    "    \n",
    "    predict_data_dir = f'data/{year}/Predict'\n",
    "    \n",
    "    models_dir = f'results/Models/{year}'\n",
    "\n",
    "    # Получить список файлов .ipnb из results\\Models\\<year>\n",
    "    file_list = tuple(filter(lambda fn: '.pickle' in fn, os.listdir(models_dir)))\n",
    "    # print(file_list)\n",
    "\n",
    "    # Сделать множество из кортежей (Название-датасета, группа), преобразовать в список, отсортировать\n",
    "    dataset_group = set()\n",
    "    for fn in file_list:\n",
    "        dataset, year, group, model = fn.split('_')\n",
    "        dataset_group |= {(dataset, group.split('гр')[1])}\n",
    "    ds_list = sorted(dataset_group)\n",
    "    # print(ds_list)\n",
    "\n",
    "    # Для каждого элемента списка создать result_list[one_model_raw: dict]\n",
    "    \n",
    "    for ds, group in ds_list:\n",
    "        result_list = []\n",
    "        ds_models = filter(lambda fn: ds in fn and group in fn, file_list)\n",
    "        for file_name in ds_models:\n",
    "            with open(f'results/Models/{year}/{file_name}', 'rb') as f:\n",
    "                model_info = pickle.load(f)\n",
    "                model = model_info['Model_full']\n",
    "                #model = model_info['Model_train']\n",
    "                \n",
    "                # Прочитать навые признаки (предикторы) для прогноза\n",
    "                X_new, y = get_river_dataset(f'{predict_data_dir}/{ds}.csv', pr_list=model_info['Predictors_list'])\n",
    "\n",
    "                # Подстановка нормированных значений для целей тестирования\n",
    "                if norms:\n",
    "                    # Подстановка норм в исходный набор признаков\n",
    "                    X_new = test_norm(X_new, model_info['Predictors_list'], model_info['Norms_data'])\n",
    "\n",
    "                print(model_info['Dataset_name'])\n",
    "                print(model_info['Predictors_list'])\n",
    "                print(model_info['Norms_data'])\n",
    "                print(model_info['Method'])\n",
    "                print(\"y\")\n",
    "                print(y)\n",
    "                print(f'R2={model_info[\"R2\"]}, R2_t={model_info[\"R2_t\"]}')\n",
    "                \n",
    "                y_predicted = np.ravel(model.predict(X_new))\n",
    "                print(\"y_predicted\")\n",
    "                print(y_predicted)\n",
    "                print('X_new')\n",
    "                print(X_new)\n",
    "                print(model)\n",
    "                model_info['Prediction'] = y_predicted[-1]\n",
    "                result_list.append(model_info)\n",
    "                # Сортировка результатов по каждому датасету\n",
    "                result_list.sort(key=lambda row: (row['Criterion'], -row['Correlation'], -row['Pm']))\n",
    "                \n",
    "                # Запись в .csv файл\n",
    "                write_dataset_csv(year, result_list, ds, fieldnames, pr_group=group, mode='forecast')\n",
    "                print('------------------------------------------------------------------------------')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63273bf-3dbe-4d10-a1d1-5935a8c3dc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d381c631-abb7-45dc-94cf-599ce7731cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вилия-Стешицы\n",
      "['S_2802', 'Smax', 'H_2802', 'X', 'X1', 'X2', 'X3', 'Xs', 'L_max', 'L_2802', 'Q12', 'Q01', 'Q02', 'Y_sum']\n",
      "{'S_max': 67.0, 'X': 112.0, 'X1': 40.0, 'X2': 33.0, 'L_max': 60.0}\n",
      "ARDRegression\n",
      "y\n",
      "[281. 292. 275. 291. 168. 195. 166. 198. 286. 277. 207. 292. 216. 198.\n",
      " 296. 220. 279. 236. 227. 233. 321. 242. 235. 281. 200. 267. 266. 200.\n",
      " 212. 281.]\n",
      "R2=-2.00674605552985, R2_t=-1.1791500589237365\n",
      "y_predicted\n",
      "[353.23500935 342.13550267 275.51363379 266.05297709 287.39806865\n",
      " 191.27263532 194.37003447 163.29662803 401.08223265 333.20296732\n",
      " 263.21403304 359.15721683 177.87215104 162.67068359 326.26224211\n",
      " 247.48882621 232.82385958 101.11191282 102.91545708 159.96123159\n",
      " 279.53330084 313.28611244 162.24445552 274.90461271 252.5747111\n",
      " 298.12079458 134.39632755 214.42106144 187.62681779 489.21665854]\n",
      "X_new\n",
      "[[ 93.    99.   139.   112.    40.    33.   184.2  146.1   60.    78.\n",
      "    6.2    4.66   4.5   32.5 ]\n",
      " [ 94.    96.   143.   112.    40.    33.   244.2  142.2   60.    78.\n",
      "    7.29   4.4    5.77  36.8 ]\n",
      " [105.   105.   140.   112.    40.    33.   155.9  102.5   60.    93.\n",
      "    5.14   3.55   3.95  26.7 ]\n",
      " [ 29.    65.   135.   112.    40.    33.   144.4  115.5   60.   108.\n",
      "    6.04  10.9    5.57  47.8 ]\n",
      " [  0.    51.   160.   112.    40.    33.    75.4  161.2   60.     0.\n",
      "    5.92  16.5   10.5   69.5 ]\n",
      " [  2.    22.   203.   112.    40.    33.   195.    90.5   60.    90.\n",
      "   10.6   11.7    9.99  68.2 ]\n",
      " [  0.    23.   146.   112.    40.    33.   107.6  117.4   60.    39.\n",
      "    5.79   6.79   8.09  43.3 ]\n",
      " [ 19.    20.   138.   112.    40.    33.   190.2   98.2   60.    44.\n",
      "    6.83   9.34   8.3   51.5 ]\n",
      " [ 50.    70.   139.   112.    40.    33.   166.9  177.4   60.    83.\n",
      "   10.    14.7    6.29  66.2 ]\n",
      " [111.   130.   148.   112.    40.    33.   222.3  141.8   60.    28.\n",
      "    5.63   4.93   4.63  32.1 ]\n",
      " [  0.    30.   165.   112.    40.    33.   195.3  151.4   60.    16.\n",
      "    6.79  12.6   12.5   66.8 ]\n",
      " [ 67.    67.   166.   112.    40.    33.   244.7  159.8   60.    59.\n",
      "   10.5   13.3    9.19  69.9 ]\n",
      " [ 31.    49.   138.   112.    40.    33.   102.1  104.    60.    31.\n",
      "    6.57   6.49   8.09  44.4 ]\n",
      " [ 31.    38.   122.   112.    40.    33.   187.1   78.1   60.    99.\n",
      "    3.4    5.21   5.08  28.7 ]\n",
      " [ 82.    91.   192.   112.    40.    33.   161.6  152.9   60.    11.\n",
      "    7.56   6.8   12.5   55.9 ]\n",
      " [ 45.    80.   136.   112.    40.    33.   207.7  127.4   60.    35.\n",
      "   10.3   11.     8.47  63.  ]\n",
      " [ 50.    90.   141.   112.    40.    33.    93.2   95.7   60.   106.\n",
      "    8.83   6.19   4.72  42.  ]\n",
      " [ 67.    67.   161.   112.    40.    33.   149.    57.6   60.    19.\n",
      "    7.66  16.1   14.5   80.3 ]\n",
      " [  0.    29.   168.   112.    40.    33.   138.3   82.7   60.    10.\n",
      "    8.35   5.48   9.09  48.  ]\n",
      " [ 66.    66.   140.   112.    40.    33.   105.8   85.2   60.    28.\n",
      "    7.23   6.85   7.23  44.9 ]\n",
      " [ 83.   101.   149.   112.    40.    33.   257.1  118.    60.    69.\n",
      "    9.91   6.63   6.11  48.  ]\n",
      " [ 85.    94.   167.   112.    40.    33.   169.7  141.8   60.    25.\n",
      "    6.57   8.24   8.28  48.5 ]\n",
      " [ 53.    53.   184.   112.    40.    33.   128.4   74.8   60.    44.\n",
      "    6.86   7.97   5.27  42.7 ]\n",
      " [ 94.   146.   128.   112.    40.    33.   189.1  128.3   60.    12.\n",
      "    5.77   6.31   7.19  40.4 ]\n",
      " [  2.    30.   199.   112.    40.    33.   185.7  132.5   60.    41.\n",
      "    9.19   6.66   7.37  49.  ]\n",
      " [  0.    37.   223.   112.    40.    33.   208.7  144.1   60.    50.\n",
      "    6.95   8.47   8.54  50.4 ]\n",
      " [ 39.    61.   186.   112.    40.    33.   192.8   64.8   60.    55.\n",
      "   13.    13.2    9.2   75.1 ]\n",
      " [  1.    67.   164.   112.    40.    33.   157.6  126.3   60.    14.\n",
      "    6.64   6.65   8.53  45.7 ]\n",
      " [  0.    60.   200.   112.    40.    33.   120.1  111.    60.     1.\n",
      "    8.3    7.49   7.18  48.5 ]\n",
      " [ 35.    48.   188.   112.    40.    33.   108.1  235.1   60.    11.\n",
      "    7.5   17.5   10.6   75.3 ]]\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('gridsearchcv',\n",
      "                 GridSearchCV(estimator=ARDRegression(), n_jobs=-1,\n",
      "                              param_grid={'alpha_1': array([1.e-07, 1.e-06, 1.e-05, 1.e-04]),\n",
      "                                          'alpha_2': array([1.e-07, 1.e-06, 1.e-05, 1.e-04]),\n",
      "                                          'lambda_1': array([1.e-07, 1.e-06, 1.e-05, 1.e-04]),\n",
      "                                          'lambda_2': array([1.e-07, 1.e-06, 1.e-05, 1.e-04])}))])\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "forecast(2024, norms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd0cbab-4846-4e5d-a052-4783097e6549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
