{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38e64d76-c788-4b3d-9eab-a19bc693668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit, OrthogonalMatchingPursuitCV\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a36d14-2f54-4edd-bd04-3ecba00281fe",
   "metadata": {},
   "source": [
    "#### Функция чтения набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dff2f17e-4fab-4bbe-9c1f-465b9638cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_river_dataset(fname, pr_list=None, y_name='H_max'):\n",
    "    pr_arr = []\n",
    "    y_arr = []\n",
    "    with open(fname, newline='') as f:\n",
    "        reader = csv.DictReader(f, delimiter=';')\n",
    "        for row in reader:\n",
    "            pr_arr_row = []\n",
    "            for pr in pr_list:\n",
    "                pr_arr_row.append(row[pr])\n",
    "\n",
    "            pr_arr.append(pr_arr_row)\n",
    "            y_arr.append(row[y_name])\n",
    "    X = np.asarray(pr_arr, dtype=np.float64)\n",
    "    y = np.asarray(y_arr, dtype=np.float64)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f85915-970a-4a02-b6e5-85aa86fa8e1d",
   "metadata": {},
   "source": [
    "#### Функция формирования тестового набора данных с подстановкой нормированных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "260024c9-0662-4996-8761-ea9bfe657cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_norm(x, pr_list, norms):\n",
    "    x_norm = np.copy(x)\n",
    "    for col, pr in enumerate(pr_list):\n",
    "        if pr in norms:\n",
    "            x_norm[:, col:col+1] = norms[pr]\n",
    "    return x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4310b5c9-b79e-427d-b7b4-68e70d34794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataset_csv(year, dataset, dataset_name, fieldnames, pr_group, mode='training'):\n",
    "    if mode == 'estimation':\n",
    "        dir_path = f'results/Estimation/{year}/{dataset_name}/group-{pr_group}/'\n",
    "        file_name = f'{dataset_name}-гр{pr_group}-Оценка.csv'\n",
    "    elif mode == 'training':\n",
    "        dir_path = f'results/Models/{year}/'\n",
    "        file_name = f'{dataset_name}-гр{pr_group}-Обучение.csv'\n",
    "    elif mode == 'forecast':\n",
    "        dir_path = f'results/Forecast/{year}/'\n",
    "        file_name = f'{dataset_name}-гр{pr_group}-Прогноз.csv'\n",
    "    else:\n",
    "        ...\n",
    "    \n",
    "    with open(\n",
    "        f'{dir_path}'\n",
    "        f'{file_name}', \n",
    "        'w', newline='', encoding='utf-8'\n",
    "    ) as csvfile:\n",
    "        \n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames, \n",
    "                                delimiter=';', extrasaction='ignore')\n",
    "        writer.writeheader()\n",
    "        writer.writerows(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafb25dc-b5b4-4ca1-a00c-1bf000b6e5bc",
   "metadata": {},
   "source": [
    "### Функция прогнозирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60d417d6-3c45-4804-b8b6-3ce9f89a3841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(year, norms=False):\n",
    "\n",
    "    fieldnames = [\n",
    "        'Predictors', \n",
    "        'Equations', \n",
    "        'Method', \n",
    "        'Criterion', \n",
    "        'Correlation', \n",
    "        'Pm',\n",
    "        'R2',        \n",
    "        'R2_t',\n",
    "        'Prediction',\n",
    "    ]\n",
    "    \n",
    "    predict_data_dir = f'data/{year}/Predict'\n",
    "    \n",
    "    models_dir = f'results/Models/{year}'\n",
    "\n",
    "    # Получить список файлов .ipnb из results\\Models\\<year>\n",
    "    file_list = tuple(filter(lambda fn: '.pickle' in fn, os.listdir(models_dir)))\n",
    "    # print(file_list)\n",
    "\n",
    "    # Сделать множество из кортежей (Название-датасета, группа), преобразовать в список, отсортировать\n",
    "    dataset_group = set()\n",
    "    for fn in file_list:\n",
    "        dataset, year, group, model = fn.split('_')\n",
    "        dataset_group |= {(dataset, group.split('гр')[1])}\n",
    "    ds_list = sorted(dataset_group)\n",
    "    # print(ds_list)\n",
    "\n",
    "    # Для каждого элемента списка создать result_list[one_model_raw: dict]\n",
    "    \n",
    "    for ds, group in ds_list:\n",
    "        result_list = []\n",
    "        ds_models = filter(lambda fn: ds in fn and group in fn, file_list)\n",
    "        for file_name in ds_models:\n",
    "            with open(f'results/Models/{year}/{file_name}', 'rb') as f:\n",
    "                model_info = pickle.load(f)\n",
    "                model = model_info['Model_full']\n",
    "                #model = model_info['Model_train']\n",
    "                \n",
    "                # Прочитать навые признаки (предикторы) для прогноза\n",
    "                X_new, y = get_river_dataset(f'{predict_data_dir}/{ds}.csv', pr_list=model_info['Predictors_list'])\n",
    "\n",
    "                # Подстановка нормированных значений для целей тестирования\n",
    "                if norms:\n",
    "                    # Подстановка норм в исходный набор признаков\n",
    "                    X_new = test_norm(X_new, model_info['Predictors_list'], model_info['Norms_data'])\n",
    "\n",
    "                print(model_info['Dataset_name'])\n",
    "                print(model_info['Predictors_list'])\n",
    "                print(model_info['Norms_data'])\n",
    "                print(model_info['Method'])\n",
    "                print(\"y\")\n",
    "                print(y)\n",
    "                print(f'R2={model_info[\"R2\"]}, R2_t={model_info[\"R2_t\"]}')\n",
    "                \n",
    "                y_predicted = np.ravel(model.predict(X_new))\n",
    "                print(\"y_predicted\")\n",
    "                print(y_predicted)\n",
    "                print('X_new')\n",
    "                print(X_new)\n",
    "                print(model)\n",
    "                model_info['Prediction'] = y_predicted[-1]\n",
    "                result_list.append(model_info)\n",
    "                # Сортировка результатов по каждому датасету\n",
    "                result_list.sort(key=lambda row: (row['Criterion'], -row['Correlation'], -row['Pm']))\n",
    "                \n",
    "                # Запись в .csv файл\n",
    "                write_dataset_csv(year, result_list, ds, fieldnames, pr_group=group, mode='forecast')\n",
    "                print('------------------------------------------------------------------------------')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63273bf-3dbe-4d10-a1d1-5935a8c3dc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d381c631-abb7-45dc-94cf-599ce7731cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вилия-Стешицы\n",
      "['S_2802', 'Smax', 'H_2802', 'X', 'X1', 'X2', 'X3', 'Xs', 'L_max', 'L_2802', 'Q12', 'Q01', 'Q02', 'Y_sum']\n",
      "None\n",
      "OMP7\n",
      "y\n",
      "[281. 292. 275. 291. 168. 195. 166. 198. 286. 277. 207. 292. 216. 198.\n",
      " 296. 220. 279. 236. 227. 233. 321. 242. 235. 281. 200. 267. 266. 200.\n",
      " 212. 281.]\n",
      "R2=0.8488614707129319, R2_t=0.8235339018679704\n",
      "y_predicted\n",
      "[300.68587497 281.40184865 287.93943673 264.08207211 176.62641453\n",
      " 230.9573563  161.5907951  201.98826667 286.15784913 287.91857213\n",
      " 198.16711425 300.5358806  210.39751134 210.66075721 294.75892495\n",
      " 253.81390639 271.86292352 227.70470309 238.01258577 229.34033746\n",
      " 281.49236724 263.20793023 244.24610926 277.72031805 210.39988732\n",
      " 252.06000311 252.05325105 192.22130295 192.32472806 268.68137472]\n",
      "X_new\n",
      "[[ 93.    99.   139.   155.9   38.5   48.   184.2  146.1   83.    78.\n",
      "    6.2    4.66   4.5   32.5 ]\n",
      " [ 94.    96.   143.   139.1   16.7   14.1  244.2  142.2   88.    78.\n",
      "    7.29   4.4    5.77  36.8 ]\n",
      " [105.   105.   140.   102.5   30.4   30.4  155.9  102.5  111.    93.\n",
      "    5.14   3.55   3.95  26.7 ]\n",
      " [ 29.    65.   135.   163.     3.3   49.   144.4  115.5  114.   108.\n",
      "    6.04  10.9    5.57  47.8 ]\n",
      " [  0.    51.   160.    36.1  134.     5.3   75.4  161.2   45.     0.\n",
      "    5.92  16.5   10.5   69.5 ]\n",
      " [  2.    22.   203.    76.1   31.6   16.5  195.    90.5   93.    90.\n",
      "   10.6   11.7    9.99  68.2 ]\n",
      " [  0.    23.   146.     3.5  119.6    3.8  107.6  117.4   40.    39.\n",
      "    5.79   6.79   8.09  43.3 ]\n",
      " [ 19.    20.   138.    92.8   29.7   22.2  190.2   98.2   60.    44.\n",
      "    6.83   9.34   8.3   51.5 ]\n",
      " [ 50.    70.   139.   185.7   23.3   38.1  166.9  177.4   96.    83.\n",
      "   10.    14.7    6.29  66.2 ]\n",
      " [111.   130.   148.   148.2   19.3   27.1  222.3  141.8   68.    28.\n",
      "    5.63   4.93   4.63  32.1 ]\n",
      " [  0.    30.   165.    34.9  148.2   37.3  195.3  151.4   39.    16.\n",
      "    6.79  12.6   12.5   66.8 ]\n",
      " [ 67.    67.   166.   159.4   55.4   54.2  244.7  159.8   59.    59.\n",
      "   10.5   13.3    9.19  69.9 ]\n",
      " [ 31.    49.   138.   121.4    3.5   20.9  102.1  104.    34.    31.\n",
      "    6.57   6.49   8.09  44.4 ]\n",
      " [ 31.    38.   122.    80.    12.4   14.7  187.1   78.1  100.    99.\n",
      "    3.4    5.21   5.08  28.7 ]\n",
      " [ 82.    91.   192.   157.7   35.    43.5  161.6  152.9   21.    11.\n",
      "    7.56   6.8   12.5   55.9 ]\n",
      " [ 45.    80.   136.   162.6   17.4   51.9  207.7  127.4   51.    35.\n",
      "   10.3   11.     8.47  63.  ]\n",
      " [ 50.    90.   141.   120.    32.8   59.    93.2   95.7  106.   106.\n",
      "    8.83   6.19   4.72  42.  ]\n",
      " [ 67.    67.   161.    55.    13.4   11.8  149.    57.6   19.    19.\n",
      "    7.66  16.1   14.5   80.3 ]\n",
      " [  0.    29.   168.   142.5   63.9  110.7  138.3   82.7   45.    10.\n",
      "    8.35   5.48   9.09  48.  ]\n",
      " [ 66.    66.   140.    84.5   29.    26.7  105.8   85.2   36.    28.\n",
      "    7.23   6.85   7.23  44.9 ]\n",
      " [ 83.   101.   149.   127.8   21.8   36.6  257.1  118.    73.    69.\n",
      "    9.91   6.63   6.11  48.  ]\n",
      " [ 85.    94.   167.   129.6   26.9    7.7  169.7  141.8   30.    25.\n",
      "    6.57   8.24   8.28  48.5 ]\n",
      " [ 53.    53.   184.    72.6   33.3   29.4  128.4   74.8   44.    44.\n",
      "    6.86   7.97   5.27  42.7 ]\n",
      " [ 94.   146.   128.   175.3   13.3   54.5  189.1  128.3   20.    12.\n",
      "    5.77   6.31   7.19  40.4 ]\n",
      " [  2.    30.   199.   108.5   29.5    0.5  185.7  132.5   47.    41.\n",
      "    9.19   6.66   7.37  49.  ]\n",
      " [  0.    37.   223.   108.7   77.2   45.4  208.7  144.1   52.    50.\n",
      "    6.95   8.47   8.54  50.4 ]\n",
      " [ 39.    61.   186.    81.9   21.    42.6  192.8   64.8   59.    55.\n",
      "   13.    13.2    9.2   75.1 ]\n",
      " [  1.    67.   164.   107.8   36.9   17.5  157.6  126.3   18.    14.\n",
      "    6.64   6.65   8.53  45.7 ]\n",
      " [  0.    60.   200.   104.     7.3    0.   120.1  111.    19.     1.\n",
      "    8.3    7.49   7.18  48.5 ]\n",
      " [ 35.    48.   188.    71.2  231.9   62.3  108.1  235.1   13.    11.\n",
      "    7.5   17.5   10.6   75.3 ]]\n",
      "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('orthogonalmatchingpursuit',\n",
      "                 OrthogonalMatchingPursuit(n_nonzero_coefs=7))])\n",
      "------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "forecast(2024, norms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd0cbab-4846-4e5d-a052-4783097e6549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
