{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64c8031c-3e29-4149-aaa3-ef3f3f0d444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cff566a-8886-47b1-a651-f3df2c864e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_river_dataset(fname, pr_list=None, y_name='h_max'):\n",
    "    pr_arr = []\n",
    "    y_arr = []\n",
    "    with open(fname, newline='') as f:\n",
    "        reader = csv.DictReader(f, delimiter=';')\n",
    "        for row in reader:\n",
    "            pr_arr_row = []\n",
    "            for col in pr_list:\n",
    "                pr_arr_row.append(row[col])\n",
    "                #print(f'{col}: {row[col]}', end='; ')\n",
    "            pr_arr.append(pr_arr_row)\n",
    "            y_arr.append(row[y_name])\n",
    "    X = np.asarray(pr_arr, dtype=np.float32)\n",
    "    y = np.asarray(y_arr, dtype=np.float32)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019a96a1-c37d-47ba-b369-2a015ec5706f",
   "metadata": {},
   "source": [
    "#### Сумма, средний, высший, низший уровни"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aa78832-4724-42e1-8e4f-8513406d88ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum(h_max):\n",
    "    return np.sum(h_max)\n",
    "    \n",
    "def get_avg(h_max):\n",
    "    return np.mean(h_max)\n",
    "    \n",
    "def get_max(h_max):\n",
    "    return np.amax(h_max)\n",
    "    \n",
    "def get_min(h_max):\n",
    "    return np.amin(h_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96dafa4-e1f7-4c26-b28d-3dfd6a2b1b14",
   "metadata": {},
   "source": [
    "#### Среднеквадратическая погрешность прогноза S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ad85fc4-c2cd-4a9f-8a0a-bb4fe4cdfe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s(h_max, h_forecast=None):\n",
    "    # Среднеквадратическая погрешность прогноза\n",
    "    n = h_max.shape[0]\n",
    "    sqr_diff = np.sum((h_max - h_forecast) ** 2) / (n - 1)\n",
    "    std = sqr_diff ** 0.5\n",
    "    return std    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893e98c4-4841-4b3f-b61b-284bc99af53d",
   "metadata": {},
   "source": [
    "#### Среднеквадратическое отклонение sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5079b8f9-3ae5-47a1-a6f3-214bdf69ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sigma(h_max):\n",
    "    # Среднеквадратическая погрешность климатическая.\n",
    "    # Рассчитывается только по всей совокупности данных.\n",
    "    return np.std(h_max, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71fe5ef3-810d-40e8-87f0-9432f139319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hmax_avg(h_max):\n",
    "    # Среднее значение h_max.\n",
    "    # Рассчитывается только по всей совокупности данных.\n",
    "    return np.mean(h_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a10fa8d-d7cd-44f4-b4f2-4f652409383f",
   "metadata": {},
   "source": [
    "#### Допустимая погрешность прогноза delta_dop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22d4648d-8e14-4c63-bcf8-6a3c2cb7a829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta_dop(sigma):\n",
    "    return 0.674 * sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c1c7ff-c4e1-4639-a877-d3b78d944dea",
   "metadata": {},
   "source": [
    "#### Критерий эффективности метода прогнозирования климатический S/sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f92739a9-3b12-44bd-b51e-4ffd73e828a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_criterion(s, sigma):\n",
    "    #print(s / sigma)\n",
    "    return s / sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaec5970-ba12-4121-8403-cd13b812b2de",
   "metadata": {},
   "source": [
    "#### Климатическая обеспеченность Pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4e1b890-8fb7-4fdd-8196-610544acee2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pk(h_max, h_max_avg, delta_dop):\n",
    "    #avg_level = np.mean(h_max)\n",
    "    diff = np.abs(h_max - h_max_avg)\n",
    "    trusted_values = diff[diff <= delta_dop]\n",
    "    m = trusted_values.shape[0]\n",
    "    n = h_max.shape[0]\n",
    "    return m / n * 100.00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a4c686-2946-4ea0-980a-172b2ff4dd64",
   "metadata": {},
   "source": [
    "#### Обеспеченность метода (оправдываемость) Pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68ca5adf-fbf3-49a4-8458-06d103bfacdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pm(h_max, h_forecast, delta_dop):\n",
    "    diff = np.abs(h_max - h_forecast) / delta_dop\n",
    "    trusted_values = diff[diff <= 1.0]\n",
    "    m = trusted_values.shape[0]\n",
    "    n = h_max.shape[0]\n",
    "    #print(m, n)\n",
    "    return m / n * 100.00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9d93f0-e243-4107-b007-cb24efbdc6f6",
   "metadata": {},
   "source": [
    "#### Корреляционное отношение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a501afb2-3736-4023-a488-a19747e54910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_ratio(criterion):\n",
    "    c_1 = (1 - criterion ** 2)\n",
    "    ro = c_1 ** 0.5 if c_1 > 0 else 0\n",
    "    return ro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c059ec96-bf22-4b2b-83f9-dc2112e0c942",
   "metadata": {},
   "source": [
    "#### Вероятная ошибка прогноза S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88e88b65-02b2-4bee-9262-b84a7a1ea70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forecast_error(s):\n",
    "    return 0.674 * s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc0abe2-cca4-4ebc-b6bf-f27c01c6b1bd",
   "metadata": {},
   "source": [
    "#### Ошибки климатического/природного прогноза для каждого года delta50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90b00b24-686d-449b-9920-aa4733a0bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta50(h_max, delta_dop, h_max_avg=None, h_max_forecast=None):\n",
    "    if h_max_forecast is None:\n",
    "        # delta50 климатическая\n",
    "        return np.abs(h_max - h_max_avg) / delta_dop\n",
    "    else:\n",
    "        # delta50 прогноза\n",
    "        return np.abs(h_max - h_max_forecast) / delta_dop\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b0cc72-ec19-437b-b6c5-8010c2e3a5bf",
   "metadata": {},
   "source": [
    "#### Функция записи в csv файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4c76ad0-d75c-4746-90dc-0d8465218463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def write_dataset_csv(dataset, filename, fieldnames):\n",
    "    with open(f'results/{filename}.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames, delimiter=';', extrasaction='ignore')\n",
    "        writer.writeheader()\n",
    "        writer.writerows(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b2d2a0-f9da-46e5-a0ae-45e8fe0c2482",
   "metadata": {},
   "source": [
    "#### Функция разделения набора данных на тренировочный и тестовый"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82db9e50-fadc-4c7f-9151-58c2b74df8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, n_test):\n",
    "    X_train = X[:-n_test]\n",
    "    y_train = y[:-n_test]\n",
    "    X_test = X[-n_test:]\n",
    "    y_test = y[-n_test:]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c3a942-95d0-4f7f-aa39-82f61624b070",
   "metadata": {},
   "source": [
    "#### Функция получения датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7628a977-9d54-4129-928c-625b4e80d107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets():\n",
    "    datasets = {\n",
    "        'Неман-Белица': 'Неман',\n",
    "        'Неман-Гродно': 'Неман',\n",
    "    }\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83168b0-64e2-4e58-a47b-f49f677a9eb4",
   "metadata": {},
   "source": [
    "#### Функция получения списка предикторов по названию датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bca1eea5-a699-4b0e-91fa-9fe6f4451ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictors(dataset_name):\n",
    "\n",
    "    datasets = get_datasets()   \n",
    "    \n",
    "    predictors_lists = {\n",
    "        'Неман': ['s_2802', 's_max', 'h', 'x', 'x1', 'x2', 'x3', 'x4', 'xs'],\n",
    "    }\n",
    "    return predictors_lists[datasets[dataset_name]]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5cf7dc-a742-42d4-9edf-b72ca98ea50c",
   "metadata": {},
   "source": [
    "#### Функция формирования проверочных прогнозов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7d9ced3-0d12-460b-8cd3-6b030f713b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_forecast(dataset_name, model, n_test=9):\n",
    "\n",
    "    ds_dir = 'data' # В константы\n",
    "\n",
    "    #datasets = get_datasets()\n",
    "    pr_list = get_predictors(dataset_name)\n",
    "    pr_list = ['year'] + pr_list\n",
    "    \n",
    "    fieldnames = [\n",
    "        'Год',\n",
    "        'Hmax фактический', 'Hф-Hср', '(Hф-Hср)^2', 'Погрешность климатических прогнозов в долях от допустимой погрешности',\n",
    "        'Hmax прогнозный', 'Hф-Hп', '(Hф-Hп)^2', 'Погрешность проверочных прогнозов в долях от допустимой погрешности',\n",
    "    ]\n",
    "\n",
    "    X, y = get_river_dataset(f'{ds_dir}/{dataset_name}.csv', pr_list=pr_list, y_name='h_max')\n",
    "\n",
    "    if n_test is not None and n_test != 0:\n",
    "        _, _, X_test, y_test = train_test_split(X, y, n_test)\n",
    "    else:\n",
    "        X_test = X\n",
    "        y_test = y\n",
    "\n",
    "    # Выделение первой колонки (года) из набора предикторов\n",
    "    years = X_test[:, 0]\n",
    "    X_test = X_test[:, 1:]\n",
    "    \n",
    "    # if n_test is not None:\n",
    "    #     X = h_max[-9:]\n",
    "    # else:\n",
    "    #     X = h_max\n",
    "    \n",
    "    # Forecast\n",
    "    h_max_forecast = model.predict(X_test)\n",
    "    \n",
    "    # Hсредний\n",
    "    h_max_avg = np.mean(y)\n",
    "\n",
    "    # H - Hсредний\n",
    "    diff_fact = y_test - h_max_avg\n",
    "\n",
    "    # (H - Hсредний) в квадрате\n",
    "    diff_fact_sqr = diff_fact ** 2\n",
    "\n",
    "    # Погрешность климатических прогнозов в долях от допустимой погрешности\n",
    "    delta_dop = get_delta_dop(get_sigma(y))\n",
    "    error_climate = get_delta50(y_test, delta_dop, h_max_avg=h_max_avg)\n",
    "\n",
    "    # H - Hпрогнозный\n",
    "    diff_forecast = y_test - h_max_forecast\n",
    "\n",
    "    # (H - Hпрогнозный) в квадрате\n",
    "    diff_forecast_sqr = diff_forecast ** 2       \n",
    "\n",
    "    # Погрешность проверочных прогнозов в долях от допустимой погрешности\n",
    "    error_forecast = get_delta50(y_test, delta_dop, h_max_forecast=h_max_forecast)\n",
    "\n",
    "    # Конкатенация массивов\n",
    "    att_tuple = (years, y_test, diff_fact, diff_fact_sqr, error_climate, h_max_forecast, diff_forecast, diff_forecast_sqr, error_forecast)\n",
    "    arr = np.column_stack(att_tuple)\n",
    "    arr = arr.tolist()\n",
    "    \n",
    "    # Запись проверочного прогноза в csv файл\n",
    "    with open(f'results/{dataset_name}-проверочный.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=';')\n",
    "        writer.writerow(fieldnames)\n",
    "        writer.writerows(arr)\n",
    "        # for i in arr:\n",
    "        #     writer.writerow(dataset)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08312297-9ca3-4e7d-be60-26969a4611e7",
   "metadata": {},
   "source": [
    "#### Функция обучения и оценки моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7dff9414-8a26-4393-b480-446307aafc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(validation=False, n_test=9, norms=False):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "    from sklearn.linear_model import Lars, LarsCV\n",
    "    from sklearn.linear_model import LassoLars\n",
    "\n",
    "    from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "    from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel, RBF\n",
    "    \n",
    "    \n",
    "    ds_dir = 'data' # В константы\n",
    "    \n",
    "    names = [\n",
    "        'LinearRegression',\n",
    "        'Ridge',\n",
    "        'Lasso',\n",
    "        'ElasticNet',\n",
    "        'ElasticNetCV',\n",
    "        'LassoLars',\n",
    "        'Lars1',\n",
    "        'Lars2',\n",
    "        'Lars3',\n",
    "        'Lars4',\n",
    "        'Lars5',\n",
    "        'Lars6',\n",
    "        'Lars7',\n",
    "        'Lars8',\n",
    "        'LarsCV',\n",
    "        \n",
    "        #'GaussianProcessRegressor',\n",
    "        \n",
    "    ]\n",
    "\n",
    "    regressors = [\n",
    "        LinearRegression(),\n",
    "        Ridge(alpha=10),\n",
    "        Lasso(alpha=100.0),\n",
    "        ElasticNet(alpha=2.0, l1_ratio=0.1),\n",
    "        ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], eps=0.01, n_alphas=1000),\n",
    "        LassoLars(alpha=1.0),\n",
    "        Lars(n_nonzero_coefs=1),\n",
    "        Lars(n_nonzero_coefs=2),\n",
    "        Lars(n_nonzero_coefs=3),\n",
    "        Lars(n_nonzero_coefs=4),\n",
    "        Lars(n_nonzero_coefs=5),\n",
    "        Lars(n_nonzero_coefs=6),\n",
    "        Lars(n_nonzero_coefs=7),\n",
    "        Lars(n_nonzero_coefs=8),\n",
    "        LarsCV(max_iter=5000, max_n_alphas=10000, cv=3),\n",
    "\n",
    "        #GaussianProcessRegressor(kernel=RBF(length_scale=1.1) + WhiteKernel() + DotProduct(), random_state=0)\n",
    "    ]\n",
    "\n",
    "    datasets = get_datasets()\n",
    "    # datasets = [\n",
    "    #     ('Неман-Белица', 'Неман'),\n",
    "    #     ('Неман-Гродно', 'Неман')\n",
    "    # ]\n",
    "\n",
    "    \n",
    "    # predictors_lists = {\n",
    "    #     'Неман': ['s_2802', 's_max', 'h', 'x', 'x1', 'x2', 'x3', 'x4', 'xs'],\n",
    "    # }\n",
    "\n",
    "    norms = {\n",
    "        \n",
    "    }\n",
    "\n",
    "    fieldnames = ['Predictors', 'Equations', 'Method', 'Criterion', 'Correlation', 'Pm']\n",
    "\n",
    "    # datasets_result = {\n",
    "    #     \"hydropost_0\": [\n",
    "    #         { model_row }\n",
    "    #         { model_row }\n",
    "    #     ],\n",
    "    #     ...,\n",
    "    #     \"hydropost_n\": [\n",
    "    #         { model_row }\n",
    "    #         { model_row }\n",
    "    #     ],\n",
    "    # }\n",
    "    \n",
    "    \n",
    "    # Итерация по датасетам\n",
    "    datasets_result = dict()\n",
    "    for ds in datasets:\n",
    "        datasets_result[ds] = []\n",
    "        # one_dataset_row = dict()\n",
    "        \n",
    "        pr_list = get_predictors(ds)\n",
    "        \n",
    "        X, y = get_river_dataset(f'{ds_dir}/{ds}.csv', pr_list=pr_list)\n",
    "\n",
    "        if validation:\n",
    "            X_train, y_train, X_test, y_test = train_test_split(X, y, n_test)\n",
    "        else:\n",
    "            X_train = X[:]\n",
    "            y_train = y[:]\n",
    "            X_test = X_train\n",
    "            y_test = y_train\n",
    "            \n",
    "        # Итерация по моделям регрессии\n",
    "        # models_list = []\n",
    "        for name, regr in zip(names, regressors):\n",
    "            one_model_row = dict()\n",
    "                \n",
    "            regr = regr.fit(X_train, y_train)\n",
    "            y_predicted = regr.predict(X_test)\n",
    "            \n",
    "            # Коэффициенты уравнения (если есть)\n",
    "            try:\n",
    "                predictors_coef = {f: c for f, c in zip(pr_list, regr.coef_) if c != 0.0}\n",
    "                predictors = \", \".join(predictors_coef.keys())\n",
    "                equation = ' '.join(str(round(c, 2))+'*'+f for f, c in predictors_coef.items())\n",
    "                equation = equation.replace(\" -\", \"-\")\n",
    "                equation = equation.replace(\" \", \" + \")\n",
    "                equation = equation.replace(\"-\", \" - \")\n",
    "    \n",
    "                one_model_row['Predictors'] = predictors\n",
    "                one_model_row['Equations'] = equation\n",
    "            except Exception:\n",
    "                one_model_row['Predictors'] = \"\"\n",
    "                one_model_row['Equations'] = \"\"\n",
    "\n",
    "            # Название метода\n",
    "            one_model_row['Method'] = name\n",
    "\n",
    "            # Расчет показателей качества по методике\n",
    "            \n",
    "            sigma = get_sigma(y)\n",
    "            delta_dop = get_delta_dop(sigma)\n",
    "            s_forecast = get_s(y_test, y_predicted)\n",
    "            \n",
    "            \n",
    "            # Критерий эффективности метода прогнозирования климатический S/sigma\n",
    "            criterion_forecast = get_criterion(s_forecast, sigma)\n",
    "            one_model_row['Criterion'] = round(criterion_forecast, 2)\n",
    "            \n",
    "            # Корреляционное отношение ro\n",
    "            correlation_forecast = get_correlation_ratio(criterion_forecast)\n",
    "            one_model_row['Correlation'] = round(correlation_forecast, 2)\n",
    "            \n",
    "            # Обеспеченность метода (оправдываемость) Pm\n",
    "            pm = get_pm(y_test, y_predicted, delta_dop)\n",
    "            one_model_row['Pm'] = round(pm, 2)\n",
    "\n",
    "            # Model\n",
    "            one_model_row['Model'] = regr\n",
    "\n",
    "            # models_list.append(one_model_row)\n",
    "            datasets_result[ds].append(one_model_row)\n",
    "\n",
    "        # Сортировка результатов по каждому датасету\n",
    "        datasets_result[ds].sort(key=lambda row: (row['Criterion'], -row['Correlation'], -row['Pm']))\n",
    "\n",
    "        # datasets_result[ds[0]].append(models_list)\n",
    "        #datasets_result.append(one_dataset_row)\n",
    "\n",
    "        # Запись в .csv файл\n",
    "        write_dataset_csv(datasets_result[ds], ds, fieldnames)\n",
    "\n",
    "    return datasets_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c6a6cd0-b14f-4e4c-a8a9-3493aafc0529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Неман-Белица': [{'Predictors': 's_2802, s_max, h, x, x1, x2, x3, x4, xs', 'Equations': '0.98*s_2802 + 0.31*s_max + 0.53*h + 1.61*x + 1.44*x1 - 0.24*x2 - 3.43*x3 + 12.16*x4 - 1.2*xs', 'Method': 'LinearRegression', 'Criterion': 0.51, 'Correlation': 0.86, 'Pm': 75.68, 'Model': LinearRegression()}, {'Predictors': 's_2802, s_max, h, x, x1, x2, x3, x4, xs', 'Equations': '1.05*s_2802 + 0.22*s_max + 0.51*h + 1.57*x + 1.4*x1 - 0.17*x2 - 0.38*x3 + 1.98*x4 - 1.15*xs', 'Method': 'Ridge', 'Criterion': 0.51, 'Correlation': 0.86, 'Pm': 75.68, 'Model': Ridge(alpha=10)}, {'Predictors': 's_2802, s_max, h, x, x1, x2, x3, x4, xs', 'Equations': '1.07*s_2802 + 0.19*s_max + 0.51*h + 1.49*x + 1.32*x1 - 0.1*x2 + 0.12*x3 + 0.3*x4 - 1.06*xs', 'Method': 'ElasticNet', 'Criterion': 0.51, 'Correlation': 0.86, 'Pm': 75.68, 'Model': ElasticNet(alpha=2.0, l1_ratio=0.1)}, {'Predictors': 's_2802, s_max, h, x, x1, x2, x3, xs', 'Equations': '1.07*s_2802 + 0.2*s_max + 0.51*h + 1.53*x + 1.36*x1 - 0.13*x2 + 0.21*x3 - 1.1*xs', 'Method': 'LassoLars', 'Criterion': 0.51, 'Correlation': 0.86, 'Pm': 75.68, 'Model': LassoLars()}, {'Predictors': 's_2802, s_max, h, x, x1, x2, x3, xs', 'Equations': '1.07*s_2802 + 0.2*s_max + 0.51*h + 1.55*x + 1.39*x1 - 0.15*x2 + 0.21*x3 - 1.12*xs', 'Method': 'Lars8', 'Criterion': 0.51, 'Correlation': 0.86, 'Pm': 75.68, 'Model': Lars(n_nonzero_coefs=8)}, {'Predictors': 's_2802, h, x, x1, x2, x3, xs', 'Equations': '1.22*s_2802 + 0.45*h + 0.93*x + 0.72*x1 + 0.32*x2 + 0.2*x3 - 0.51*xs', 'Method': 'Lars7', 'Criterion': 0.52, 'Correlation': 0.85, 'Pm': 78.38, 'Model': Lars(n_nonzero_coefs=7)}, {'Predictors': 's_2802, h, x, x1, x2, x3', 'Equations': '1.21*s_2802 + 0.41*h + 0.4*x + 0.16*x1 + 0.7*x2 + 0.2*x3', 'Method': 'Lars6', 'Criterion': 0.54, 'Correlation': 0.84, 'Pm': 81.08, 'Model': Lars(n_nonzero_coefs=6)}, {'Predictors': 's_2802, h, x, x1, x2, x3', 'Equations': '1.18*s_2802 + 0.37*h + 0.34*x + 0.07*x1 + 0.66*x2 + 0.18*x3', 'Method': 'Lasso', 'Criterion': 0.55, 'Correlation': 0.84, 'Pm': 81.08, 'Model': Lasso(alpha=100.0)}, {'Predictors': 's_2802, h, x, x2, x3', 'Equations': '1.15*s_2802 + 0.35*h + 0.3*x + 0.64*x2 + 0.17*x3', 'Method': 'Lars5', 'Criterion': 0.55, 'Correlation': 0.83, 'Pm': 81.08, 'Model': Lars(n_nonzero_coefs=5)}, {'Predictors': 's_2802, h, x, x2, x3', 'Equations': '1.11*s_2802 + 0.29*h + 0.26*x + 0.48*x2 + 0.15*x3', 'Method': 'LarsCV', 'Criterion': 0.57, 'Correlation': 0.82, 'Pm': 78.38, 'Model': LarsCV(cv=3, max_iter=5000, max_n_alphas=10000)}, {'Predictors': 's_2802, s_max, h, x, x1, x2, x3', 'Equations': '0.69*s_2802 + 0.36*s_max + 0.33*h + 0.34*x + 0.09*x1 + 0.39*x2 + 0.19*x3', 'Method': 'ElasticNetCV', 'Criterion': 0.58, 'Correlation': 0.81, 'Pm': 78.38, 'Model': ElasticNetCV(eps=0.01, l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1],\n",
      "             n_alphas=1000)}, {'Predictors': 's_2802, h, x, x3', 'Equations': '0.98*s_2802 + 0.09*h + 0.16*x + 0.06*x3', 'Method': 'Lars4', 'Criterion': 0.68, 'Correlation': 0.73, 'Pm': 67.57, 'Model': Lars(n_nonzero_coefs=4)}, {'Predictors': 's_2802, x, x3', 'Equations': '0.93*s_2802 + 0.11*x + 0.02*x3', 'Method': 'Lars3', 'Criterion': 0.72, 'Correlation': 0.69, 'Pm': 64.86, 'Model': Lars(n_nonzero_coefs=3)}, {'Predictors': 's_2802, x', 'Equations': '0.91*s_2802 + 0.1*x', 'Method': 'Lars2', 'Criterion': 0.73, 'Correlation': 0.69, 'Pm': 62.16, 'Model': Lars(n_nonzero_coefs=2)}, {'Predictors': 's_2802', 'Equations': '0.68*s_2802', 'Method': 'Lars1', 'Criterion': 0.79, 'Correlation': 0.61, 'Pm': 54.05, 'Model': Lars(n_nonzero_coefs=1)}], 'Неман-Гродно': [{'Predictors': 's_2802, s_max, h, x, x1, x2, x3, x4, xs', 'Equations': '0.6*s_2802 + 1.17*s_max + 0.5*h - 0.88*x - 0.85*x1 + 2.55*x2 + 20.49*x3 - 67.53*x4 + 1.04*xs', 'Method': 'LinearRegression', 'Criterion': 0.52, 'Correlation': 0.85, 'Pm': 85.71, 'Model': LinearRegression()}, {'Predictors': 's_2802, s_max, h, x, x1, x2, x3, x4, xs', 'Equations': '0.79*s_2802 + 1.06*s_max + 0.45*h - 0.84*x - 0.78*x1 + 2.47*x2 + 14.36*x3 - 46.99*x4 + 0.98*xs', 'Method': 'LassoLars', 'Criterion': 0.52, 'Correlation': 0.85, 'Pm': 82.86, 'Model': LassoLars()}, {'Predictors': 's_2802, s_max, h, x, x1, x2, x3, x4, xs', 'Equations': '1.11*s_2802 + 0.88*s_max + 0.37*h - 0.8*x - 0.71*x1 + 2.39*x2 + 3.71*x3 - 11.38*x4 + 0.91*xs', 'Method': 'Ridge', 'Criterion': 0.54, 'Correlation': 0.84, 'Pm': 82.86, 'Model': Ridge(alpha=10)}, {'Predictors': 's_2802, s_max, h, x, x1, x2, x3, x4, xs', 'Equations': '1.21*s_2802 + 0.81*s_max + 0.35*h - 0.76*x - 0.64*x1 + 2.31*x2 + 0.88*x3 - 1.9*x4 + 0.86*xs', 'Method': 'ElasticNet', 'Criterion': 0.55, 'Correlation': 0.84, 'Pm': 80.0, 'Model': ElasticNet(alpha=2.0, l1_ratio=0.1)}, {'Predictors': 's_2802, s_max, h, x, x1, x2, x3, xs', 'Equations': '1.22*s_2802 + 0.8*s_max + 0.34*h - 0.77*x - 0.66*x1 + 2.33*x2 + 0.32*x3 + 0.87*xs', 'Method': 'Lars8', 'Criterion': 0.55, 'Correlation': 0.83, 'Pm': 80.0, 'Model': Lars(n_nonzero_coefs=8)}, {'Predictors': 's_2802, s_max, h, x, x2, x3, xs', 'Equations': '1.67*s_2802 + 0.38*s_max + 0.23*h - 0.16*x + 1.04*x2 + 0.31*x3 + 0.2*xs', 'Method': 'Lasso', 'Criterion': 0.57, 'Correlation': 0.82, 'Pm': 77.14, 'Model': Lasso(alpha=100.0)}, {'Predictors': 's_2802, s_max, h, x1, x2, x3, xs', 'Equations': '1.79*s_2802 + 0.27*s_max + 0.2*h + 0.15*x1 + 0.7*x2 + 0.3*x3 + 0.02*xs', 'Method': 'Lars7', 'Criterion': 0.58, 'Correlation': 0.81, 'Pm': 77.14, 'Model': Lars(n_nonzero_coefs=7)}, {'Predictors': 's_2802, s_max, h, x1, x2, x3', 'Equations': '1.8*s_2802 + 0.26*s_max + 0.19*h + 0.14*x1 + 0.65*x2 + 0.29*x3', 'Method': 'Lars6', 'Criterion': 0.59, 'Correlation': 0.81, 'Pm': 80.0, 'Model': Lars(n_nonzero_coefs=6)}, {'Predictors': 's_2802, s_max, h, x2, x3', 'Equations': '1.93*s_2802 + 0.06*s_max + 0.08*h + 0.24*x2 + 0.19*x3', 'Method': 'Lars5', 'Criterion': 0.62, 'Correlation': 0.79, 'Pm': 80.0, 'Model': Lars(n_nonzero_coefs=5)}, {'Predictors': 's_2802, h, x2, x3', 'Equations': '1.98*s_2802 + 0.04*h + 0.1*x2 + 0.16*x3', 'Method': 'Lars4', 'Criterion': 0.63, 'Correlation': 0.78, 'Pm': 80.0, 'Model': Lars(n_nonzero_coefs=4)}, {'Predictors': 's_2802, h, x3', 'Equations': '1.98*s_2802 + 0.02*h + 0.14*x3', 'Method': 'Lars3', 'Criterion': 0.64, 'Correlation': 0.77, 'Pm': 77.14, 'Model': Lars(n_nonzero_coefs=3)}, {'Predictors': 's_2802, x3', 'Equations': '1.9*s_2802 + 0.06*x3', 'Method': 'Lars2', 'Criterion': 0.65, 'Correlation': 0.76, 'Pm': 80.0, 'Model': Lars(n_nonzero_coefs=2)}, {'Predictors': 's_2802, h, x3', 'Equations': '1.91*s_2802 + 0.0*h + 0.07*x3', 'Method': 'ElasticNetCV', 'Criterion': 0.65, 'Correlation': 0.76, 'Pm': 77.14, 'Model': ElasticNetCV(eps=0.01, l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1],\n",
      "             n_alphas=1000)}, {'Predictors': 's_2802, h, x3', 'Equations': '1.93*s_2802 + 0.01*h + 0.09*x3', 'Method': 'LarsCV', 'Criterion': 0.65, 'Correlation': 0.76, 'Pm': 77.14, 'Model': LarsCV(cv=3, max_iter=5000, max_n_alphas=10000)}, {'Predictors': 's_2802', 'Equations': '1.83*s_2802', 'Method': 'Lars1', 'Criterion': 0.66, 'Correlation': 0.75, 'Pm': 77.14, 'Model': Lars(n_nonzero_coefs=1)}]}\n"
     ]
    }
   ],
   "source": [
    "result = compare_models(validation=False, n_test=None)\n",
    "print(result, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2e0d6ee-54cc-4626-922d-97d17aaf74c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получить лучшую модель по датасету с индексом [0] из результатов функции обучения и оценки моделей\n",
    "dataset_name = 'Неман-Белица'\n",
    "best_dataset_model = result[dataset_name][0]['Model']\n",
    "verify_forecast(dataset_name, best_dataset_model, n_test=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd911561-b1fd-4132-91a9-4b2b764bb7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prediction = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06a41f7-345e-4f4e-a651-306876865f40",
   "metadata": {},
   "source": [
    "### Формирование набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "878a3a90-4937-413c-98ff-5dc2b2c1196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pr_list = ['s_2802', 's_max', 'h', 'x', 'x1', 'x2', 'x3', 'x4', 'xs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c3a7499-5ecf-4382-829d-c3e5a0500be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_list = ['s_2802', 's_max', 'h', 'x', 'x1', 'x2', 'x3', 'xs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfb41ade-215a-4420-b76f-5e81115a0860",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/Неман-Белица-2022.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mget_river_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/Неман-Белица-2022.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpr_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpr_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m, in \u001b[0;36mget_river_dataset\u001b[1;34m(fname, pr_list, y_name)\u001b[0m\n\u001b[0;32m      2\u001b[0m pr_arr \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m y_arr \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      5\u001b[0m     reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictReader(f, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m reader:\n",
      "File \u001b[1;32mC:\\projects\\pkogo\\env_ogo\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/Неман-Белица-2022.csv'"
     ]
    }
   ],
   "source": [
    "X, y = get_river_dataset('data/Неман-Белица-2022.csv', pr_list=pr_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bd715b-125f-48e9-8780-f5a6bc6c312e",
   "metadata": {},
   "source": [
    "### Нормализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77780ebb-7cef-47b2-a65d-c14898422bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Стандартизация\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_train_st = scaler.transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c199635-480b-495d-a2a4-c79580537d8c",
   "metadata": {},
   "source": [
    "### Модели регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14db5e2-b870-4764-8db1-da9ba2fa86c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5080edf-9f4a-459c-8f4c-033034e313f8",
   "metadata": {},
   "source": [
    "#### Линейная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f8efa5-9408-4ce6-a712-025837d75589",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression(fit_intercept=True)\n",
    "regr = regr.fit(X, y)\n",
    "y_predicted = regr.predict(X)\n",
    "print(y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a77f409-16ae-48d4-a547-3bd6d9bba69f",
   "metadata": {},
   "source": [
    "### Вычисление статистики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049a9b9a-974b-4d26-ad42-1b9eda9f4a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Среднеквадратическое отклонение sigma\n",
    "sigma = get_sigma('Неман-Белица')\n",
    "print(f'Среднеквадратическое отклонение sigma = {sigma}')\n",
    "\n",
    "# Допустимая погрешность прогноза delta_dop\n",
    "delta_dop = get_delta_dop(sigma)\n",
    "print(f'Допустимая погрешность прогноза sigma_dop = {delta_dop}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ccef1d-8aaa-46d5-a0fd-6bf75c30ff7f",
   "metadata": {},
   "source": [
    "#### Климат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc073128-1161-47dd-a214-31f9a98b4e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Статистика максимального уровня\n",
    "sum_level = get_sum(y)\n",
    "avg_level = get_avg(y)\n",
    "max_level = get_max(y)\n",
    "min_level = get_min(y)\n",
    "print(f'Сумма {sum_level}, Средний {avg_level}, Высший {max_level}, Низший {min_level}')\n",
    "\n",
    "# Среднеквадратическая погрешность климатическая S\n",
    "s_climate = get_s(y)\n",
    "print(f'Среднеквадратическая погрешность климатическая: {s_climate}')\n",
    "\n",
    "# Критерий эффективности метода прогнозирования климатический S/sigma\n",
    "criterion_climate = get_criterion(s_climate, sigma)\n",
    "print(f'Критерий эффективности метода прогнозирования климатический S/sigma = {criterion_climate}')\n",
    "\n",
    "# Климатическая обеспеченность Pk\n",
    "pk = get_pk(y, delta_dop)\n",
    "print(f'Климатическая обеспеченность Pk, % = {pk}')\n",
    "\n",
    "# Корреляционное отношение ro\n",
    "ro_climate = get_correlation_ratio(criterion_climate)\n",
    "print(f'Корреляционное отношение климатическое ro = {ro_climate}')\n",
    "\n",
    "# Вероятная погрешность прогноза delta50\n",
    "delta50_climate = get_delta50(s_climate)\n",
    "print(f'Вероятная погрешность климатическая delta50 = {delta50_climate}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965ca06a-3618-4b00-a278-bf19d2e03ee6",
   "metadata": {},
   "source": [
    "#### Прогноз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9d28ce-11ae-4619-9e02-eb54144fa75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Коэффициенты регрессии\n",
    "print(regr.intercept_, regr.coef_)\n",
    "\n",
    "# Среднеквадратическая погрешность климатическая S\n",
    "s_forecast = get_s(y, y_predicted)\n",
    "print(f'Среднеквадратическая погрешность прогноза: {s_forecast}')\n",
    "\n",
    "# Критерий эффективности метода прогнозирования климатический S/sigma\n",
    "criterion_forecast = get_criterion(s_forecast, sigma)\n",
    "print(f'Критерий эффективности метода прогнозирования S/sigma = {criterion_forecast}')\n",
    "\n",
    "# Обеспеченность метода (оправдываемость) Pm\n",
    "pm = get_pm(y, y_predicted, delta_dop)\n",
    "print(f'Обеспеченность метода (оправдываемость) Pm, % = {pm}')\n",
    "\n",
    "# Корреляционное отношение ro\n",
    "ro_forecast = get_correlation_ratio(criterion_forecast)\n",
    "print(f'Корреляционное отношение ro = {ro_forecast}')\n",
    "\n",
    "# Вероятная погрешность прогноза delta50\n",
    "delta50_forecast = get_delta50(s_forecast)\n",
    "print(f'Вероятная погрешность прогноза delta50 = {delta50_forecast}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f3da721c-ac86-4afe-8af7-a0cec9e1f0e5",
   "metadata": {},
   "source": [
    "289.5946 [ 37.161125    6.904029   17.490725   72.53384    45.801464   -3.9831583\n",
    "   9.45435   -39.79478  ]\n",
    "Среднеквадратическая погрешность прогноза: 37.40044945975472\n",
    "Критерий эффективности метода прогнозирования S/sigma = 0.40215537053499695\n",
    "36 37\n",
    "Обеспеченность метода (оправдываемость) Pm, % = 97.2972972972973\n",
    "Корреляционное отношение ro = 0.9155714379281714\n",
    "Вероятная погрешность прогноза delta50 = 25.20790293587468"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b5865c-5c42-4079-8a2a-05e24c3d0adc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e535fc-4253-4ce7-a2c0-c19f2101938c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0936d16e-d458-490e-bca8-3596f4d77655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03eaa67-7e57-48bd-b667-162ba1f0323f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1de70d2b-7908-4523-b473-27368557404f",
   "metadata": {},
   "source": [
    "### Обучающий набор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89754005-cbf6-4afa-8ace-094582bf7230",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_qnt = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a90d07a-6509-48fc-b2b9-aa3f6d23d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:-test_qnt]\n",
    "X_test = X[-test_qnt:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a0224c-d141-45b2-ae86-7fc169248baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y[:-test_qnt]\n",
    "y_test = y[-test_qnt:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f58c02-117c-42f4-bcb5-b7d4f29373de",
   "metadata": {},
   "source": [
    "## Этап нормализации"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff019d4b-92a5-4737-9034-c312ab94b0b0",
   "metadata": {},
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_sc = scaler.transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "838be35f-7ab9-4c14-80bf-cba05aa462c0",
   "metadata": {},
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "regr = regr.fit(X_train, y_train)\n",
    "y_predicted = regr.predict(X_test)\n",
    "print(y_predicted)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4cd1f4e0-5cf9-4288-b6cc-7416c8c71f3f",
   "metadata": {},
   "source": [
    "regr_sc = linear_model.LinearRegression()\n",
    "regr_sc = regr.fit(X_train_sc, y_train)\n",
    "y_predicted = regr.predict(X_train_sc)\n",
    "print(y_predicted)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57659058-8ce4-49a6-85ea-0135fe0c82f6",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regr = RandomForestRegressor()\n",
    "regr = regr.fit(X_train, y_train)\n",
    "y_predicted = regr.predict(X_train)\n",
    "print(y_predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
