{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64c8031c-3e29-4149-aaa3-ef3f3f0d444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cff566a-8886-47b1-a651-f3df2c864e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_river_dataset(fname, pr_list=None, y_name='h_max'):\n",
    "    pr_arr = []\n",
    "    y_arr = []\n",
    "    with open(fname, newline='') as f:\n",
    "        reader = csv.DictReader(f, delimiter=';')\n",
    "        for row in reader:\n",
    "            pr_arr_row = []\n",
    "            for col in pr_list:\n",
    "                pr_arr_row.append(row[col])\n",
    "\n",
    "            pr_arr.append(pr_arr_row)\n",
    "            y_arr.append(row[y_name])\n",
    "    X = np.asarray(pr_arr, dtype=np.float32)\n",
    "    y = np.asarray(y_arr, dtype=np.float32)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019a96a1-c37d-47ba-b369-2a015ec5706f",
   "metadata": {},
   "source": [
    "#### Сумма, средний, высший, низший уровни"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aa78832-4724-42e1-8e4f-8513406d88ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum(h_max):\n",
    "    return np.sum(h_max)\n",
    "    \n",
    "def get_avg(h_max):\n",
    "    return np.mean(h_max)\n",
    "    \n",
    "def get_max(h_max):\n",
    "    return np.amax(h_max)\n",
    "    \n",
    "def get_min(h_max):\n",
    "    return np.amin(h_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96dafa4-e1f7-4c26-b28d-3dfd6a2b1b14",
   "metadata": {},
   "source": [
    "#### Среднеквадратическая погрешность прогноза S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ad85fc4-c2cd-4a9f-8a0a-bb4fe4cdfe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s(h_max, h_forecast=None):\n",
    "    # Среднеквадратическая погрешность прогноза\n",
    "    n = h_max.shape[0]\n",
    "    sqr_diff = np.sum((h_max - np.around(h_forecast, 0)) ** 2) / (n - 1)\n",
    "    std = sqr_diff ** 0.5\n",
    "    return std    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893e98c4-4841-4b3f-b61b-284bc99af53d",
   "metadata": {},
   "source": [
    "#### Среднеквадратическое отклонение sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5079b8f9-3ae5-47a1-a6f3-214bdf69ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sigma(h_max):\n",
    "    # Среднеквадратическая погрешность климатическая.\n",
    "    # Рассчитывается только по всей совокупности данных.\n",
    "    n = h_max.shape[0]\n",
    "    hmax_avg = (h_max - round(np.mean(h_max)))\n",
    "    hmax_avg_sqr = hmax_avg ** 2\n",
    "    sum_avg_sqr = np.sum(hmax_avg_sqr)\n",
    "    std = (sum_avg_sqr / (n-1)) ** 0.5\n",
    "    ##np.std(h_max, ddof=1)\n",
    "    return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71fe5ef3-810d-40e8-87f0-9432f139319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hmax_avg(h_max):\n",
    "    # Среднее значение h_max.\n",
    "    # Рассчитывается только по всей совокупности данных.\n",
    "    return np.mean(h_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a10fa8d-d7cd-44f4-b4f2-4f652409383f",
   "metadata": {},
   "source": [
    "#### Допустимая погрешность прогноза delta_dop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22d4648d-8e14-4c63-bcf8-6a3c2cb7a829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta_dop(sigma):\n",
    "    return 0.674 * sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c1c7ff-c4e1-4639-a877-d3b78d944dea",
   "metadata": {},
   "source": [
    "#### Критерий эффективности метода прогнозирования климатический S/sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f92739a9-3b12-44bd-b51e-4ffd73e828a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_criterion(s, sigma):\n",
    "    return s / sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaec5970-ba12-4121-8403-cd13b812b2de",
   "metadata": {},
   "source": [
    "#### Климатическая обеспеченность Pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4e1b890-8fb7-4fdd-8196-610544acee2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pk(h_max, h_max_avg, delta_dop):\n",
    "    #avg_level = np.mean(h_max)\n",
    "    diff = np.abs(h_max - h_max_avg) / delta_dop\n",
    "    trusted_values = diff[diff <= 1.0]\n",
    "    m = trusted_values.shape[0]\n",
    "    n = h_max.shape[0]\n",
    "    return m / n * 100.00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a4c686-2946-4ea0-980a-172b2ff4dd64",
   "metadata": {},
   "source": [
    "#### Обеспеченность метода (оправдываемость) Pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68ca5adf-fbf3-49a4-8458-06d103bfacdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pm(h_max, h_forecast, delta_dop):\n",
    "    diff = np.abs(h_max - h_forecast) / delta_dop\n",
    "    trusted_values = diff[diff <= 1.0]\n",
    "    m = trusted_values.shape[0]\n",
    "    n = h_max.shape[0]\n",
    "    return m / n * 100.00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9d93f0-e243-4107-b007-cb24efbdc6f6",
   "metadata": {},
   "source": [
    "#### Корреляционное отношение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a501afb2-3736-4023-a488-a19747e54910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_ratio(criterion):\n",
    "    c_1 = (1 - criterion ** 2)\n",
    "    ro = c_1 ** 0.5 if c_1 > 0 else 0\n",
    "    return ro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c059ec96-bf22-4b2b-83f9-dc2112e0c942",
   "metadata": {},
   "source": [
    "#### Вероятная ошибка прогноза S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88e88b65-02b2-4bee-9262-b84a7a1ea70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forecast_error(s):\n",
    "    return 0.674 * s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc0abe2-cca4-4ebc-b6bf-f27c01c6b1bd",
   "metadata": {},
   "source": [
    "#### Ошибки климатического/природного прогноза для каждого года delta50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90b00b24-686d-449b-9920-aa4733a0bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta50(h_max, delta_dop, h_max_avg=None, h_max_forecast=None):\n",
    "    if h_max_forecast is None:\n",
    "        # delta50 климатическая\n",
    "        return (h_max - h_max_avg) / delta_dop\n",
    "    else:\n",
    "        # delta50 прогноза\n",
    "        return (h_max - h_max_forecast) / delta_dop\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b0cc72-ec19-437b-b6c5-8010c2e3a5bf",
   "metadata": {},
   "source": [
    "#### Функция записи в csv файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4c76ad0-d75c-4746-90dc-0d8465218463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def write_dataset_csv(dataset, filename, fieldnames):\n",
    "    with open(f'results/{filename}.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames, delimiter=';', extrasaction='ignore')\n",
    "        writer.writeheader()\n",
    "        writer.writerows(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b2d2a0-f9da-46e5-a0ae-45e8fe0c2482",
   "metadata": {},
   "source": [
    "#### Функция разделения набора данных на тренировочный и тестовый"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82db9e50-fadc-4c7f-9151-58c2b74df8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, n_test):\n",
    "    X_train = X[:-n_test]\n",
    "    y_train = y[:-n_test]\n",
    "    X_test = X[-n_test:]\n",
    "    y_test = y[-n_test:]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c3a942-95d0-4f7f-aa39-82f61624b070",
   "metadata": {},
   "source": [
    "#### Функция получения датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7628a977-9d54-4129-928c-625b4e80d107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets():\n",
    "    datasets = {\n",
    "        'Неман-Белица': 'Неман',\n",
    "        'Неман-Гродно': 'Неман',\n",
    "    }\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83168b0-64e2-4e58-a47b-f49f677a9eb4",
   "metadata": {},
   "source": [
    "#### Функция получения списка предикторов по названию датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bca1eea5-a699-4b0e-91fa-9fe6f4451ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictors(dataset_name):\n",
    "\n",
    "    datasets = get_datasets()   \n",
    "    \n",
    "    predictors_lists = {\n",
    "        'Неман': ['s_2802', 's_max', 'h', 'x', 'x1', 'x2', 'x3', 'x4', 'xs'],\n",
    "    }\n",
    "\n",
    "    # predictors_lists = {\n",
    "    #     'Неман': (\n",
    "    #         ['s_2802', 's_max', 'h', 'x', 'x1', 'x2', 'x3', 'x4', 'xs'],\n",
    "    #         ['s_max', 'h', 'x', 'x1', 'x3'],\n",
    "    #         ['s_2802', 'h', 'x2', 'x3', 'xs'],\n",
    "    #     )\n",
    "    # }\n",
    "    return predictors_lists[datasets[dataset_name]]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08312297-9ca3-4e7d-be60-26969a4611e7",
   "metadata": {},
   "source": [
    "#### Функция обучения и оценки моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dff9414-8a26-4393-b480-446307aafc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(n_test=None, norms=False):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "    from sklearn.linear_model import Lars, LarsCV\n",
    "    from sklearn.linear_model import LassoLars\n",
    "\n",
    "    from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "    from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel, RBF\n",
    "    \n",
    "    \n",
    "    ds_dir = 'data' # В константы\n",
    "    \n",
    "    names = [\n",
    "        \n",
    "        #'Ridge',\n",
    "        #'Lasso',\n",
    "        #'ElasticNet',\n",
    "        #'ElasticNetCV',\n",
    "        #'LassoLars',\n",
    "        #'Lars1',\n",
    "        #'Lars2',\n",
    "        #'Lars3',\n",
    "        #'Lars4',\n",
    "        #'Lars5',\n",
    "        #'Lars6',\n",
    "        #'Lars7',\n",
    "        #'Lars8',\n",
    "        \n",
    "        'LarsCV',\n",
    "        'LinearRegression',\n",
    "        \n",
    "        #'GaussianProcessRegressor',\n",
    "        \n",
    "    ]\n",
    "\n",
    "    regressors = [\n",
    "        \n",
    "        #Ridge(alpha=10),\n",
    "        #Lasso(alpha=100.0),\n",
    "        #ElasticNet(alpha=2.0, l1_ratio=0.1),\n",
    "        #ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], eps=0.01, n_alphas=1000),\n",
    "        #LassoLars(alpha=1.0),\n",
    "        #Lars(n_nonzero_coefs=1),\n",
    "        #Lars(n_nonzero_coefs=2),\n",
    "        #Lars(n_nonzero_coefs=3),\n",
    "        #Lars(n_nonzero_coefs=4),\n",
    "        #Lars(n_nonzero_coefs=5),\n",
    "        #Lars(n_nonzero_coefs=6),\n",
    "        #Lars(n_nonzero_coefs=7),\n",
    "        #Lars(n_nonzero_coefs=8),\n",
    "        \n",
    "        LarsCV(max_iter=5000, max_n_alphas=10000, cv=5),\n",
    "        LinearRegression(),\n",
    "        #GaussianProcessRegressor(kernel=RBF(length_scale=1.1) + WhiteKernel() + DotProduct(), random_state=0)\n",
    "    ]\n",
    "\n",
    "    datasets = get_datasets()\n",
    "    \n",
    "    norms = {\n",
    "        \n",
    "    }\n",
    "\n",
    "    fieldnames = ['Predictors', 'Equations', 'Method', 'Criterion', 'Correlation', 'Pm']\n",
    "\n",
    "    # datasets_result = {\n",
    "    #     \"hydropost_0\": [\n",
    "    #         { model_row }\n",
    "    #         { model_row }\n",
    "    #     ],\n",
    "    #     ...,\n",
    "    #     \"hydropost_n\": [\n",
    "    #         { model_row }\n",
    "    #         { model_row }\n",
    "    #     ],\n",
    "    # }\n",
    "    \n",
    "    \n",
    "    # Итерация по датасетам\n",
    "    datasets_result = dict()\n",
    "    for ds in datasets:\n",
    "        result_list = []\n",
    "        #datasets_result[ds] = []\n",
    "        # one_dataset_row = dict()\n",
    "        \n",
    "        pr_list = get_predictors(ds)\n",
    "        \n",
    "        X, y = get_river_dataset(f'{ds_dir}/{ds}.csv', pr_list=pr_list)\n",
    "\n",
    "        if n_test is not None and n_test != 0:\n",
    "            X_train, y_train, X_test, y_test = train_test_split(X, y, n_test)\n",
    "        else:\n",
    "            X_train = X[:]\n",
    "            y_train = y[:]\n",
    "            X_test = X_train\n",
    "            y_test = y_train\n",
    "            \n",
    "        # Итерация по моделям регрессии\n",
    "        # models_list = []\n",
    "        for name, regr in zip(names, regressors):\n",
    "            one_model_row = dict()\n",
    "                \n",
    "            regr.fit(X_train, y_train)\n",
    "            y_predicted = regr.predict(X_test)\n",
    "            \n",
    "            # Коэффициенты уравнения (если есть)\n",
    "            try:\n",
    "                predictors_coef = {f: c for f, c in zip(pr_list, regr.coef_) if c != 0.0}\n",
    "                predictors = \", \".join(predictors_coef.keys())\n",
    "                equation = ' '.join(str(round(c, 2))+'*'+f for f, c in predictors_coef.items())\n",
    "                equation = equation.replace(\" -\", \"-\")\n",
    "                equation = equation.replace(\" \", \" + \")\n",
    "                equation = equation.replace(\"-\", \" - \")\n",
    "    \n",
    "                one_model_row['Predictors'] = predictors\n",
    "                one_model_row['Equations'] = equation\n",
    "            except Exception:\n",
    "                one_model_row['Predictors'] = \"\"\n",
    "                one_model_row['Equations'] = \"\"\n",
    "\n",
    "            # Название метода\n",
    "            one_model_row['Method'] = name\n",
    "\n",
    "            # Расчет показателей качества по методике\n",
    "            \n",
    "            # Среднее значение максимального уровня по всей выборке\n",
    "            h_max_avg = round(get_hmax_avg(y), 0)\n",
    "            one_model_row['H_avg'] = h_max_avg\n",
    "            \n",
    "            # Среднеквадратическое отклонение\n",
    "            sigma = get_sigma(y)\n",
    "            one_model_row['Sigma'] = sigma\n",
    "\n",
    "            # Допустимая погрешность прогноза\n",
    "            delta_dop = get_delta_dop(sigma)\n",
    "            one_model_row['Delta_dop'] = delta_dop\n",
    "\n",
    "            # Обеспеченность климатическая Pk\n",
    "            pk = get_pk(y_test, h_max_avg, delta_dop)\n",
    "            one_model_row['Pk'] = round(pk, 1)\n",
    "\n",
    "            # Обеспеченность метода (оправдываемость) Pm\n",
    "            pm = get_pm(y_test, y_predicted, delta_dop)\n",
    "            one_model_row['Pm'] = round(pm, 1)\n",
    "\n",
    "            # Среднеквадратическая погрешность прогноза\n",
    "            s_forecast = get_s(y_test, y_predicted)\n",
    "            one_model_row['S'] = s_forecast\n",
    "            \n",
    "            # Критерий эффективности метода прогнозирования климатический S/sigma\n",
    "            criterion_forecast = get_criterion(s_forecast, sigma)\n",
    "            one_model_row['Criterion'] = criterion_forecast\n",
    "\n",
    "            # Критерий эффективности метода прогнозирования климатический S/sigma в квадрате\n",
    "            criterion_sqr = get_criterion(s_forecast, sigma) ** 2.0\n",
    "            one_model_row['Criterion_sqr'] = criterion_sqr\n",
    "            \n",
    "            # Корреляционное отношение ro\n",
    "            correlation_forecast = get_correlation_ratio(criterion_forecast)\n",
    "            one_model_row['Correlation'] = correlation_forecast\n",
    "                        \n",
    "            # Model\n",
    "            one_model_row['Model'] = regr\n",
    "\n",
    "            # models_list.append(one_model_row)\n",
    "            result_list.append(one_model_row)\n",
    "\n",
    "        # Сортировка результатов по каждому датасету\n",
    "        result_list.sort(key=lambda row: (row['Criterion'], -row['Correlation'], -row['Pm']))\n",
    "\n",
    "        datasets_result[ds] = result_list\n",
    "        #datasets_result.append(one_dataset_row)\n",
    "\n",
    "        # Запись в .csv файл\n",
    "        write_dataset_csv(result_list, ds, fieldnames)\n",
    "\n",
    "        verify_forecast(ds, result_list[0]['Model'], n_test=n_test)    \n",
    "\n",
    "    \n",
    "\n",
    "    return datasets_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1d848a-fd25-4827-989d-013f2e6d1fbd",
   "metadata": {},
   "source": [
    "#### Функция формирования проверочных прогнозов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7d9ced3-0d12-460b-8cd3-6b030f713b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_forecast(dataset_name, model, n_test=None):\n",
    "\n",
    "    ds_dir = 'data' # В константы\n",
    "\n",
    "    pr_list = get_predictors(dataset_name)\n",
    "    pr_list = ['year'] + pr_list\n",
    "    \n",
    "    # fieldnames = [\n",
    "    #     'Год',\n",
    "    #     'Hmax фактический', 'Hф-Hср', '(Hф-Hср)^2', 'Погрешность климатических прогнозов в долях от допустимой погрешности',\n",
    "    #     'Hmax прогнозный', 'Hф-Hп', '(Hф-Hп)^2', 'Погрешность проверочных прогнозов в долях от допустимой погрешности',\n",
    "    # ]\n",
    "    fieldnames = [\n",
    "        'Year',\n",
    "        'Hmax fact', 'Hf-Havg', '(Hf-Havg)^2', 'Error climate',\n",
    "        'Hmax forecast', 'Hf-Hfor', '(Hf-Hfor)^2', 'Error forecast',\n",
    "    ]\n",
    "\n",
    "    X, y = get_river_dataset(f'{ds_dir}/{dataset_name}.csv', pr_list=pr_list, y_name='h_max')\n",
    "\n",
    "    if n_test is not None and n_test != 0:\n",
    "        _, _, X_test, y_test = train_test_split(X, y, n_test)\n",
    "    else:\n",
    "        X_test = X\n",
    "        y_test = y\n",
    "\n",
    "    # Выделение первой колонки (года) из набора предикторов\n",
    "    years = np.asarray(X_test[:, 0], dtype=np.float32)\n",
    "    X_test = np.asarray(X_test[:, 1:], dtype=np.float32)\n",
    "    \n",
    "    # Forecast\n",
    "    h_max_forecast = np.around(model.predict(X_test))\n",
    "    \n",
    "    # Hсредний\n",
    "    h_max_avg = np.around(np.mean(y))\n",
    "\n",
    "    # H - Hсредний\n",
    "    diff_fact = y_test - h_max_avg\n",
    "\n",
    "    # (H - Hсредний) в квадрате\n",
    "    diff_fact_sqr = diff_fact ** 2\n",
    "\n",
    "    # Погрешность климатических прогнозов в долях от допустимой погрешности\n",
    "    delta_dop = get_delta_dop(get_sigma(y))\n",
    "    error_climate = np.around(get_delta50(y_test, delta_dop, h_max_avg=h_max_avg), decimals=2)\n",
    "\n",
    "    # H - Hпрогнозный\n",
    "    diff_forecast = y_test - h_max_forecast\n",
    "\n",
    "    # (H - Hпрогнозный) в квадрате\n",
    "    diff_forecast_sqr = diff_forecast ** 2       \n",
    "\n",
    "    # Погрешность проверочных прогнозов в долях от допустимой погрешности\n",
    "    error_forecast = np.around(get_delta50(y_test, delta_dop, h_max_forecast=h_max_forecast), decimals=2)\n",
    "\n",
    "    # Конкатенация массивов\n",
    "    att_tuple = (years, y_test, diff_fact, diff_fact_sqr, error_climate, h_max_forecast, diff_forecast, diff_forecast_sqr, error_forecast)\n",
    "    arr = np.column_stack(att_tuple)\n",
    "    arr = arr.tolist()\n",
    "\n",
    "    # Обеспеченность метода (оправдываемость) Pm\n",
    "    pm = get_pm(y_test, h_max_forecast, delta_dop)\n",
    "    \n",
    "    # Запись проверочного прогноза в csv файл\n",
    "    with open(f'results/{dataset_name}-проверочный.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=';')\n",
    "        writer.writerow(fieldnames)\n",
    "        writer.writerows(arr)\n",
    "        \n",
    "      \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48df2181-e85a-449e-bbd2-41e64908cb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Неман-Белица\n",
      "LinearRegression,\n",
      "H_avg=290.0,\n",
      "Sigma=72.81693179168947,\n",
      "Delta_dop=49.07861202759871,\n",
      "Pk=37.8,\n",
      "Pm=75.7,\n",
      "S=37.23498951852201,\n",
      "Criterion=0.5113507065230618,\n",
      "Criterion^2=0.26147954506163446,\n",
      "Correlation=0.8593721283229783,\n",
      "Model=LinearRegression()\n",
      "\n",
      "\n",
      "          LarsCV,\n",
      "H_avg=290.0,\n",
      "Sigma=72.81693179168947,\n",
      "Delta_dop=49.07861202759871,\n",
      "Pk=37.8,\n",
      "Pm=78.4,\n",
      "S=41.43602833820399,\n",
      "Criterion=0.5690438654671941,\n",
      "Criterion^2=0.3238109208258461,\n",
      "Correlation=0.8223071683830525,\n",
      "Model=LarsCV(cv=5, max_iter=5000, max_n_alphas=10000)\n",
      "\n",
      "\n",
      "Неман-Гродно\n",
      "LinearRegression,\n",
      "H_avg=280.0,\n",
      "Sigma=96.45206063117574,\n",
      "Delta_dop=65.00868886541245,\n",
      "Pk=51.4,\n",
      "Pm=85.7,\n",
      "S=50.236206769502765,\n",
      "Criterion=0.5208411975935033,\n",
      "Criterion^2=0.2712755531106348,\n",
      "Correlation=0.8536535871706773,\n",
      "Model=LinearRegression()\n",
      "\n",
      "\n",
      "          LarsCV,\n",
      "H_avg=280.0,\n",
      "Sigma=96.45206063117574,\n",
      "Delta_dop=65.00868886541245,\n",
      "Pk=51.4,\n",
      "Pm=80.0,\n",
      "S=58.19920153080736,\n",
      "Criterion=0.6034002918129041,\n",
      "Criterion^2=0.36409191215989783,\n",
      "Correlation=0.7974384539512138,\n",
      "Model=LarsCV(cv=5, max_iter=5000, max_n_alphas=10000)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = compare_models(n_test=0)\n",
    "for key in result:\n",
    "    print(key)\n",
    "    for r in result[key]:\n",
    "        print(\n",
    "            f\"{r['Method']:>16},\\n\" \n",
    "            f\"H_avg={r['H_avg']},\\n\" \n",
    "            f\"Sigma={r['Sigma']},\\n\" \n",
    "            f\"Delta_dop={r['Delta_dop']},\\n\" \n",
    "            f\"Pk={r['Pk']},\\n\"\n",
    "            f\"Pm={r['Pm']},\\n\"\n",
    "            f\"S={r['S']},\\n\"\n",
    "            f\"Criterion={r['Criterion']},\\n\" \n",
    "            f\"Criterion^2={r['Criterion_sqr']},\\n\"\n",
    "            f\"Correlation={r['Correlation']},\\n\"            \n",
    "            f\"Model={r['Model']}\\n\\n\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d4e9e82-4391-4b5b-9a19-89386105288e",
   "metadata": {},
   "source": [
    "# Получить лучшую модель по датасету с индексом [0] из результатов функции обучения и оценки моделей\n",
    "dataset_name = 'Неман-Белица'\n",
    "ds_row = result[dataset_name][0]\n",
    "print(f\"{ds_row['Method']:>16}: Criterion={ds_row['Criterion']}, Correlation={ds_row['Correlation']}, Pm={ds_row['Pm']}, Model={ds_row['Model']}\")\n",
    "\n",
    "best_dataset_model = ds_row['Model']\n",
    "verify_forecast(dataset_name, best_dataset_model, n_test=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03eaa67-7e57-48bd-b667-162ba1f0323f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
