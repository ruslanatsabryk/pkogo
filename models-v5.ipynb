{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75541273-d8a0-40fe-b676-e024f18f6b41",
   "metadata": {},
   "source": [
    "#### Импорт необходимых объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d31a67-e1f4-4f73-b386-b54e9da7cea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lars\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.linear_model import TweedieRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "from sklearn.linear_model import QuantileRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386c8264-7ddd-469d-9581-8eefb3f13322",
   "metadata": {},
   "source": [
    "#### Функция чтения набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cff566a-8886-47b1-a651-f3df2c864e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_river_dataset(fname, pr_list=None, y_name='H_max'):\n",
    "    pr_arr = []\n",
    "    y_arr = []\n",
    "    with open(fname, newline='') as f:\n",
    "        reader = csv.DictReader(f, delimiter=';')\n",
    "        for row in reader:\n",
    "            pr_arr_row = []\n",
    "            for pr in pr_list:\n",
    "                pr_arr_row.append(row[pr])\n",
    "\n",
    "            pr_arr.append(pr_arr_row)\n",
    "            y_arr.append(row[y_name])\n",
    "    X = np.asarray(pr_arr, dtype=np.float64)\n",
    "    y = np.asarray(y_arr, dtype=np.float64)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019a96a1-c37d-47ba-b369-2a015ec5706f",
   "metadata": {},
   "source": [
    "#### Сумма, средний, высший, низший уровни"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aa78832-4724-42e1-8e4f-8513406d88ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum(h_max):\n",
    "    return np.sum(h_max)\n",
    "    \n",
    "def get_avg(h_max):\n",
    "    return np.mean(h_max)\n",
    "    \n",
    "def get_max(h_max):\n",
    "    return np.amax(h_max)\n",
    "    \n",
    "def get_min(h_max):\n",
    "    return np.amin(h_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96dafa4-e1f7-4c26-b28d-3dfd6a2b1b14",
   "metadata": {},
   "source": [
    "#### Среднеквадратическая погрешность прогноза S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ad85fc4-c2cd-4a9f-8a0a-bb4fe4cdfe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s(h_max, h_forecast=None):\n",
    "    # Среднеквадратическая погрешность прогноза\n",
    "    n = h_max.shape[0]\n",
    "    sqr_diff = np.sum((h_max - h_forecast) ** 2) / (n - 1)\n",
    "    std = sqr_diff ** 0.5\n",
    "    return std    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893e98c4-4841-4b3f-b61b-284bc99af53d",
   "metadata": {},
   "source": [
    "#### Среднеквадратическое отклонение sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5079b8f9-3ae5-47a1-a6f3-214bdf69ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sigma(h_max):\n",
    "    # Среднеквадратическая погрешность климатическая.\n",
    "    # Рассчитывается только по всей совокупности данных.\n",
    "    return np.std(h_max, ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6ebdd8-9291-4612-9573-b5e6464fc07e",
   "metadata": {},
   "source": [
    "#### Среднее значение максимальных уровней воды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71fe5ef3-810d-40e8-87f0-9432f139319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hmax_avg(h_max):\n",
    "    # Среднее значение h_max.\n",
    "    # Рассчитывается только по всей совокупности данных.\n",
    "    return np.mean(h_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a10fa8d-d7cd-44f4-b4f2-4f652409383f",
   "metadata": {},
   "source": [
    "#### Допустимая погрешность прогноза delta_dop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22d4648d-8e14-4c63-bcf8-6a3c2cb7a829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta_dop(sigma):\n",
    "    return 0.674 * sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c1c7ff-c4e1-4639-a877-d3b78d944dea",
   "metadata": {},
   "source": [
    "#### Критерий эффективности метода прогнозирования климатический S/sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f92739a9-3b12-44bd-b51e-4ffd73e828a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_criterion(s, sigma):\n",
    "    return s / sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaec5970-ba12-4121-8403-cd13b812b2de",
   "metadata": {},
   "source": [
    "#### Климатическая обеспеченность Pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4e1b890-8fb7-4fdd-8196-610544acee2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pk(h_max, h_max_avg, delta_dop):\n",
    "    diff = np.abs(h_max - h_max_avg) / delta_dop\n",
    "    trusted_values = diff[diff <= 1.0]\n",
    "    m = trusted_values.shape[0]\n",
    "    n = h_max.shape[0]\n",
    "    return m / n * 100.00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a4c686-2946-4ea0-980a-172b2ff4dd64",
   "metadata": {},
   "source": [
    "#### Обеспеченность метода (оправдываемость) Pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68ca5adf-fbf3-49a4-8458-06d103bfacdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pm(h_max, h_forecast, delta_dop):\n",
    "    diff = np.abs(h_max - h_forecast) / delta_dop\n",
    "    trusted_values = diff[diff <= 1.0]\n",
    "    m = trusted_values.shape[0]\n",
    "    n = h_max.shape[0]\n",
    "    return m / n * 100.00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9d93f0-e243-4107-b007-cb24efbdc6f6",
   "metadata": {},
   "source": [
    "#### Корреляционное отношение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a501afb2-3736-4023-a488-a19747e54910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_ratio(criterion):\n",
    "    c_1 = (1 - criterion ** 2)\n",
    "    ro = c_1 ** 0.5 if c_1 > 0 else 0\n",
    "    return ro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c059ec96-bf22-4b2b-83f9-dc2112e0c942",
   "metadata": {},
   "source": [
    "#### Вероятная ошибка прогноза S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88e88b65-02b2-4bee-9262-b84a7a1ea70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forecast_error(s):\n",
    "    return 0.674 * s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc0abe2-cca4-4ebc-b6bf-f27c01c6b1bd",
   "metadata": {},
   "source": [
    "#### Ошибки климатического/природного прогноза для каждого года delta50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90b00b24-686d-449b-9920-aa4733a0bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta50(h_max, delta_dop, h_max_avg=None, h_max_forecast=None):\n",
    "    if h_max_forecast is None:\n",
    "        # delta50 климатическая\n",
    "        return (h_max - h_max_avg) / delta_dop\n",
    "    else:\n",
    "        # delta50 прогноза\n",
    "        return (h_max - h_max_forecast) / delta_dop\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b0cc72-ec19-437b-b6c5-8010c2e3a5bf",
   "metadata": {},
   "source": [
    "#### Функция записи в csv файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4c76ad0-d75c-4746-90dc-0d8465218463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def write_dataset_csv(dataset, dataset_name, fieldnames, pr_group):\n",
    "    with open(\n",
    "        f'results/{dataset_name}/group-{pr_group}/'\n",
    "        f'{dataset_name}-гр{pr_group}.csv', \n",
    "        'w', newline='', encoding='utf-8'\n",
    "    ) as csvfile:\n",
    "        \n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames, \n",
    "                                delimiter=';', extrasaction='ignore')\n",
    "        writer.writeheader()\n",
    "        writer.writerows(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b2d2a0-f9da-46e5-a0ae-45e8fe0c2482",
   "metadata": {},
   "source": [
    "#### Функция разделения набора данных на тренировочный и тестовый"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82db9e50-fadc-4c7f-9151-58c2b74df8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, n_test):\n",
    "    X_train = X[:-n_test]\n",
    "    y_train = y[:-n_test]\n",
    "    X_test = X[-n_test:]\n",
    "    y_test = y[-n_test:]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2719a5f9-176e-473d-8ce7-b7744d9c6e19",
   "metadata": {},
   "source": [
    "#### Функция формирования тестового набора данных с подстановкой нормированных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b464d45-843c-4792-ab02-2819edddee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_norm(x, pr_list, norms):\n",
    "    x_norm = np.copy(x)\n",
    "    for col, pr in enumerate(pr_list):\n",
    "        if pr in norms:\n",
    "            x_norm[:, col:col+1] = norms[pr]\n",
    "    return x_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c3a942-95d0-4f7f-aa39-82f61624b070",
   "metadata": {},
   "source": [
    "#### Функция получения датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7628a977-9d54-4129-928c-625b4e80d107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets():\n",
    "    datasets = {\n",
    "        'Неман-Белица': 'Неман',\n",
    "        # 'Неман-Гродно': 'Неман',\n",
    "        # 'Неман-Мосты': 'Неман',\n",
    "        # 'Неман-Столбцы': 'Неман',\n",
    "    }\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83168b0-64e2-4e58-a47b-f49f677a9eb4",
   "metadata": {},
   "source": [
    "#### Функция получения списка предикторов по названию датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bca1eea5-a699-4b0e-91fa-9fe6f4451ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictors(dataset_name, pr_group):\n",
    "\n",
    "    datasets = get_datasets()   \n",
    "    predictors_lists = {\n",
    "        'Неман': (\n",
    "            ['S_2802', 'Smax', 'H_2802', 'X', 'X1', 'X2', 'X3', 'Xs'],\n",
    "            ['Smax', 'H_2802', 'X', 'X1', 'X3'],\n",
    "            ['S_2802', 'H_2802', 'X2', 'X3', 'Xs'],\n",
    "        )\n",
    "    }\n",
    "    return predictors_lists[datasets[dataset_name]][pr_group]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2790ff38-4843-40b6-ac40-a9efec555315",
   "metadata": {},
   "source": [
    "#### Функция получения нормированных значений предикторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a741f9dd-31c9-4ea6-a1a8-b2b684b05013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norms(dataset_name):\n",
    "    norms_list = {\n",
    "        'Неман-Белица': {'X1': 46.0, 'X2':35.0},\n",
    "        'Неман-Гродно': {'X1': 36.0, 'X2':26.0},\n",
    "        'Неман-Мосты': {'x1': 40.0, 'x2':31.0},\n",
    "        'Неман-Столбцы': {'x1': 43.0, 'x2':34.0},\n",
    "    }\n",
    "    return norms_list[dataset_name]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08312297-9ca3-4e7d-be60-26969a4611e7",
   "metadata": {},
   "source": [
    "#### Функция обучения и оценки моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dff9414-8a26-4393-b480-446307aafc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(pr_group, n_test=None, norms=True, top_best=None):\n",
    "    \n",
    "    ds_dir = 'data'\n",
    "    \n",
    "    names = [\n",
    "        'LinearRegression',\n",
    "        'Ridge',\n",
    "        'Lasso',\n",
    "        'ElasticNet',\n",
    "        'Lars1',\n",
    "        'Lars2',\n",
    "        'Lars3',\n",
    "        'Lars4',\n",
    "        'Lars5',\n",
    "        'LassoLars',\n",
    "        'OMP1',\n",
    "        'OMP2',\n",
    "        'OMP3',\n",
    "        'OMP4',\n",
    "        'OMP5',\n",
    "        'BayesianRidge',\n",
    "        'ARDRegression',\n",
    "        'SGDRegressor', \n",
    "        'PassiveAggressiveRegressor',\n",
    "        'HuberRegressor',\n",
    "        'TheilSenRegressor',\n",
    "        'QuantileRegressor',               \n",
    "    ]\n",
    "\n",
    "    # Инициализация генератора случайных чисел для\n",
    "    # для обеспечения воспроизводимости результатов\n",
    "    rng = np.random.RandomState(0)\n",
    "\n",
    "    # Наборы гиперпараметров моделей для алгоритма кроссвалидации\n",
    "    # Гиперпараметры для Ridge, Lasso, ElasticNet, LassoLars, HuberRegressor\n",
    "    alphas = np.logspace(-4, 3, num=100)\n",
    "    \n",
    "    # Гиперпараметры для ElasticNet\n",
    "    l1_ratio = np.linspace(0.01, 1.0, num=50)\n",
    "    \n",
    "    # Гиперпараметры для BayesianRidge\n",
    "    alphas_init = np.linspace(0.5, 2, 5)\n",
    "    lambdas_init = np.logspace(-3, 1, num=5)\n",
    "    \n",
    "    # Гиперпараметры для ARDRegression\n",
    "    alphas_lambdas = np.logspace(-7, -4, num=4)\n",
    "    \n",
    "    # Гиперпараметры для SGDRegressor\n",
    "    losses = ['squared_error', 'huber', \n",
    "              'epsilon_insensitive', 'squared_epsilon_insensitive']\n",
    "    sgd_alphas = np.logspace(-4, 1, num=100)\n",
    "   \n",
    "    # Гиперпараметры для PassiveAggressiveRegressor\n",
    "    cc = np.linspace(0.1, 1.5, 50)\n",
    "    \n",
    "    # Гиперпараметры для HuberRegressor\n",
    "    epsilons = np.append(np.linspace(1.1, 2.0, 10), [1.35])\n",
    "    \n",
    "    # Гиперпараметры для TheilSenRegressor\n",
    "    n_subsamples = np.arange(6, 24)\n",
    "    \n",
    "    # Гиперпараметры для QuantileRegressor\n",
    "    q_alphas = np.linspace(0, 2, 20)    \n",
    "           \n",
    "    \n",
    "    regressors = [\n",
    "        LinearRegression(),\n",
    "        \n",
    "        GridSearchCV(\n",
    "            estimator=Ridge(random_state=rng), \n",
    "            param_grid={\"alpha\": alphas}\n",
    "        ),\n",
    "        \n",
    "        GridSearchCV(\n",
    "            estimator=Lasso(random_state=rng), \n",
    "            param_grid={\"alpha\": alphas}\n",
    "        ),\n",
    "        \n",
    "        GridSearchCV(\n",
    "            estimator=ElasticNet(random_state=rng), \n",
    "            param_grid={\"alpha\": alphas, \"l1_ratio\": l1_ratio}, \n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        \n",
    "        Lars(n_nonzero_coefs=1),\n",
    "        Lars(n_nonzero_coefs=2),\n",
    "        Lars(n_nonzero_coefs=3),\n",
    "        Lars(n_nonzero_coefs=4),\n",
    "        Lars(n_nonzero_coefs=5),\n",
    "        \n",
    "        GridSearchCV(\n",
    "            estimator=LassoLars(random_state=rng), \n",
    "            param_grid={\"alpha\": alphas}\n",
    "        ),\n",
    "        \n",
    "        OrthogonalMatchingPursuit(n_nonzero_coefs=1),\n",
    "        OrthogonalMatchingPursuit(n_nonzero_coefs=2),\n",
    "        OrthogonalMatchingPursuit(n_nonzero_coefs=3),\n",
    "        OrthogonalMatchingPursuit(n_nonzero_coefs=4),\n",
    "        OrthogonalMatchingPursuit(n_nonzero_coefs=5),\n",
    "        \n",
    "        GridSearchCV(\n",
    "            estimator=BayesianRidge(),\n",
    "            param_grid={\"alpha_init\": alphas_init, \"lambda_init\": lambdas_init}, \n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        \n",
    "        GridSearchCV(\n",
    "            estimator=ARDRegression(), \n",
    "            param_grid={\"alpha_1\": alphas_lambdas, \"alpha_2\": alphas_lambdas,\n",
    "                        \"lambda_1\": alphas_lambdas,\"lambda_2\": alphas_lambdas}, \n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        \n",
    "        GridSearchCV(\n",
    "            estimator=SGDRegressor(random_state=rng), \n",
    "            param_grid={\"loss\": losses, \"alpha\": sgd_alphas}, \n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        \n",
    "        GridSearchCV(\n",
    "            estimator=PassiveAggressiveRegressor(random_state=rng), \n",
    "            param_grid={\"C\": cc}, \n",
    "            n_jobs=-1, \n",
    "            cv=3\n",
    "        ),\n",
    "        \n",
    "        GridSearchCV(\n",
    "            estimator=HuberRegressor(), \n",
    "            param_grid={\"epsilon\": epsilons, \"alpha\": alphas}, \n",
    "            n_jobs=-1 \n",
    "        ),\n",
    "        \n",
    "        GridSearchCV(\n",
    "            estimator=TheilSenRegressor(random_state=rng), \n",
    "            param_grid={\"n_subsamples\": n_subsamples}, \n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        \n",
    "        GridSearchCV(\n",
    "            estimator=QuantileRegressor(), \n",
    "            param_grid={\"alpha\": q_alphas}, \n",
    "            n_jobs=-1\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    datasets = get_datasets()\n",
    "\n",
    "    fieldnames = [\n",
    "        'Predictors', \n",
    "        'Equations', \n",
    "        'Method', \n",
    "        'Criterion', \n",
    "        'Correlation', \n",
    "        'Pm'\n",
    "    ]\n",
    "\n",
    "    # Описание структуры данных переменной datasets_result\n",
    "    # datasets_result = {\n",
    "    #     \"hydropost_0\": [\n",
    "    #         { model_row }\n",
    "    #         { model_row }\n",
    "    #     ],\n",
    "    #     ...,\n",
    "    #     \"hydropost_n\": [\n",
    "    #         { model_row }\n",
    "    #         { model_row }\n",
    "    #     ],\n",
    "    # }\n",
    "    \n",
    "    \n",
    "    # Итерация по датасетам\n",
    "    datasets_result = dict()\n",
    "    for ds in datasets:\n",
    "        result_list = []\n",
    "        \n",
    "        pr_list = get_predictors(ds, pr_group)\n",
    "        \n",
    "        X, y = get_river_dataset(f'{ds_dir}/{ds}.csv', pr_list=pr_list)\n",
    "\n",
    "        if n_test is not None and n_test != 0:\n",
    "            X_train, y_train, X_test, y_test = train_test_split(X, y, n_test)\n",
    "        else:\n",
    "            X_train = X[:]\n",
    "            y_train = y[:]\n",
    "            X_test = X_train\n",
    "            y_test = y_train\n",
    "\n",
    "        if norms:\n",
    "            norms = get_norms(ds)\n",
    "            X_test = test_norm(X_test, pr_list, norms)\n",
    "            \n",
    "        # Итерация по моделям регрессии\n",
    "        for name, regr in zip(names, regressors):\n",
    "            one_model_row = dict()\n",
    "\n",
    "            regr.fit(X_train, y_train)\n",
    "                \n",
    "            y_predicted = np.ravel(regr.predict(X_test))           \n",
    "\n",
    "            try:\n",
    "                coef = regr.best_estimator_.coef_\n",
    "                intercept = regr.best_estimator_.intercept_\n",
    "                \n",
    "                if isinstance(intercept, np.ndarray):\n",
    "                    intercept = intercept[0]\n",
    "            except Exception as error:\n",
    "                \n",
    "                coef = regr.coef_\n",
    "                intercept = regr.intercept_\n",
    "                \n",
    "                if isinstance(intercept, np.ndarray):\n",
    "                    intercept = intercept[0]\n",
    "                print(error)\n",
    "                \n",
    "            # Коэффициенты уравнения (если есть)\n",
    "            coef = np.around(np.ravel(coef), 3)\n",
    "            intercept = round(intercept, 3)\n",
    "            try:\n",
    "                predictors_coef = {f: c for f, c \n",
    "                                   in zip(pr_list, coef) if c != 0.0}\n",
    "                \n",
    "                predictors = \", \".join(predictors_coef.keys())\n",
    "                \n",
    "                equation = (\n",
    "                    str(intercept) \n",
    "                    + ' ' \n",
    "                    + ' '.join(str(c) + '*' \n",
    "                               + f for f, c in predictors_coef.items())\n",
    "                )\n",
    "                \n",
    "                equation = equation.replace(\" -\", \"-\")\n",
    "                equation = equation.replace(\" \", \" + \")\n",
    "                equation = equation.replace(\"-\", \" - \")\n",
    "    \n",
    "                one_model_row['Predictors'] = predictors\n",
    "                one_model_row['Equations'] = equation\n",
    "            except Exception as error:\n",
    "                print(error)\n",
    "                one_model_row['Predictors'] = \"\"\n",
    "                one_model_row['Equations'] = \"\"\n",
    "\n",
    "            # Название датасета\n",
    "            one_model_row['Dataset_name'] = ds\n",
    "\n",
    "            # Группа предикторов\n",
    "            one_model_row['Group'] = pr_group\n",
    "                \n",
    "            # Название метода\n",
    "            one_model_row['Method'] = name\n",
    "\n",
    "            # Расчет показателей качества по методике\n",
    "\n",
    "            # Сумма, максимум, минимум максимальных уровней\n",
    "            one_model_row['H_sum'] = get_sum(y)\n",
    "            one_model_row['H_max'] = get_max(y)\n",
    "            one_model_row['H_min'] = get_min(y)\n",
    "            \n",
    "            # Среднее значение максимального уровня по всей выборке\n",
    "            h_max_avg = get_hmax_avg(y)\n",
    "            one_model_row['H_avg'] = h_max_avg\n",
    "            \n",
    "            # Среднеквадратическое отклонение\n",
    "            sigma = get_sigma(y)\n",
    "            one_model_row['Sigma'] = sigma\n",
    "\n",
    "            # Допустимая погрешность прогноза\n",
    "            delta_dop = get_delta_dop(sigma)\n",
    "            one_model_row['Delta_dop'] = delta_dop\n",
    "\n",
    "            # Обеспеченность климатическая Pk\n",
    "            pk = get_pk(y_test, h_max_avg, delta_dop)\n",
    "            one_model_row['Pk'] = pk\n",
    "\n",
    "            # Обеспеченность метода (оправдываемость) Pm\n",
    "            pm = get_pm(y_test, y_predicted, delta_dop)\n",
    "            one_model_row['Pm'] = pm\n",
    "\n",
    "            # Среднеквадратическая погрешность прогноза\n",
    "            s_forecast = get_s(y_test, y_predicted)\n",
    "            one_model_row['S'] = s_forecast\n",
    "            \n",
    "            # Критерий эффективности метода прогнозирования \n",
    "            # климатический S/sigma\n",
    "            criterion_forecast = get_criterion(s_forecast, sigma)\n",
    "            one_model_row['Criterion'] = criterion_forecast\n",
    "\n",
    "            # Критерий эффективности метода прогнозирования \n",
    "            # климатический S/sigma в квадрате\n",
    "            criterion_sqr = get_criterion(s_forecast, sigma) ** 2.0\n",
    "            one_model_row['Criterion_sqr'] = criterion_sqr\n",
    "            \n",
    "            # Корреляционное отношение ro\n",
    "            correlation_forecast = get_correlation_ratio(criterion_forecast)\n",
    "            one_model_row['Correlation'] = correlation_forecast\n",
    "                        \n",
    "            # Обученная модель\n",
    "            one_model_row['Model'] = regr\n",
    "\n",
    "            # Добавление результатов модели в результирующий список по датасету\n",
    "            result_list.append(one_model_row)\n",
    "\n",
    "        # Сортировка результатов по каждому датасету\n",
    "        result_list.sort(\n",
    "            key=lambda row: (row['Criterion'], \n",
    "                             -row['Correlation'], \n",
    "                             -row['Pm'])\n",
    "        )\n",
    "\n",
    "        datasets_result[ds] = result_list\n",
    "\n",
    "        # Запись в .csv файл\n",
    "        write_dataset_csv(result_list, ds, fieldnames, pr_group=pr_group)\n",
    "\n",
    "        for i, rl in enumerate(result_list):\n",
    "            if top_best is not None:\n",
    "                if i >= top_best:\n",
    "                    break\n",
    "            verify_forecast(ds, rl, i, pr_group=pr_group, n_test=n_test)\n",
    "\n",
    "    return datasets_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1d848a-fd25-4827-989d-013f2e6d1fbd",
   "metadata": {},
   "source": [
    "#### Функция формирования проверочных прогнозов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7d9ced3-0d12-460b-8cd3-6b030f713b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_forecast(dataset_name, rl, num, pr_group, n_test=None, norms=True):\n",
    "\n",
    "    ds_dir = 'data'\n",
    "\n",
    "    pr_list = get_predictors(dataset_name, pr_group)\n",
    "    pr_list = ['year'] + pr_list\n",
    "    \n",
    "    fieldnames = [\n",
    "        '№', \n",
    "        'Год',\n",
    "        'Hmax фактический', \n",
    "        'Hф-Hср', \n",
    "        '(Hф-Hср)^2', \n",
    "        \n",
    "        'δ50% Погрешность климатических прогнозов '\n",
    "        'в долях от допустимой погрешности',\n",
    "        \n",
    "        'Hmax прогнозный', \n",
    "        'Hф-Hп', \n",
    "        '(Hф-Hп)^2', \n",
    "        \n",
    "        'δ50% Погрешность проверочных прогнозов '\n",
    "        'в долях от допустимой погрешности',\n",
    "    ]\n",
    "\n",
    "    X, y = get_river_dataset(\n",
    "        f'{ds_dir}/{dataset_name}.csv', pr_list=pr_list, y_name='H_max'\n",
    "    )\n",
    "\n",
    "    if n_test is not None and n_test != 0:\n",
    "        _, _, X_test, y_test = train_test_split(X, y, n_test)\n",
    "    else:\n",
    "        X_test = X\n",
    "        y_test = y\n",
    "\n",
    "    if norms:\n",
    "        norms = get_norms(dataset_name)\n",
    "        X_test = test_norm(X_test, pr_list, norms)\n",
    "\n",
    "    # Выделение первой колонки (года) из набора предикторов\n",
    "    years = X_test[:, 0]\n",
    "    X_test = X_test[:, 1:]\n",
    "    \n",
    "    # Forecast\n",
    "    h_max_forecast = np.ravel(rl['Model'].predict(X_test))\n",
    "    \n",
    "    # Hсредний\n",
    "    h_max_avg = np.mean(y)\n",
    "\n",
    "    # H - Hсредний\n",
    "    diff_fact = y_test - h_max_avg\n",
    "\n",
    "    # (H - Hсредний) в квадрате\n",
    "    diff_fact_sqr = diff_fact ** 2\n",
    "\n",
    "    # Погрешность климатических прогнозов в долях от допустимой погрешности\n",
    "    delta_dop = get_delta_dop(get_sigma(y))\n",
    "    error_climate = get_delta50(y_test, delta_dop, h_max_avg=h_max_avg)\n",
    "\n",
    "    # H - Hпрогнозный\n",
    "    diff_forecast = y_test - h_max_forecast\n",
    "\n",
    "    # (H - Hпрогнозный) в квадрате\n",
    "    diff_forecast_sqr = diff_forecast ** 2       \n",
    "\n",
    "    # Погрешность проверочных прогнозов в долях от допустимой погрешности\n",
    "    error_forecast = get_delta50(\n",
    "        y_test, delta_dop, h_max_forecast=h_max_forecast\n",
    "    )\n",
    "\n",
    "    # Номер по порядку\n",
    "    rows_num = y_test.shape[0]\n",
    "    npp = np.arange(1, rows_num + 1, 1)\n",
    "\n",
    "    # Конкатенация массивов\n",
    "    att_tuple = (\n",
    "        npp, \n",
    "        years, \n",
    "        y_test, \n",
    "        diff_fact, \n",
    "        diff_fact_sqr, \n",
    "        error_climate, \n",
    "        h_max_forecast, \n",
    "        diff_forecast, \n",
    "        diff_forecast_sqr, \n",
    "        error_forecast\n",
    "    )\n",
    "    \n",
    "    arr = np.column_stack(att_tuple)\n",
    "    arr = arr.tolist()\n",
    "\n",
    "    # Обеспеченность метода (оправдываемость) Pm\n",
    "    pm = get_pm(y_test, h_max_forecast, delta_dop)\n",
    "    \n",
    "    # Запись проверочного прогноза в csv файл\n",
    "    with open(\n",
    "        f'results/{dataset_name}/group-{pr_group}/{dataset_name}'\n",
    "        f'-проверочный-гр{pr_group}-{num:0>2}.csv', \n",
    "        'w', \n",
    "        newline='', \n",
    "        encoding='utf-8'\n",
    "    ) as csvfile:\n",
    "        \n",
    "        stat_header = (\n",
    "            f\"Таблица  - \"\n",
    "            f\"Проверочные прогнозы максимумов весеннего половодья\\n\"\n",
    "            f\"р.{rl['Dataset_name']}\\n\"\n",
    "            f\"Предикторы:;; {rl['Predictors']}\\n\"\n",
    "            f\"Уравнение:;; {rl['Equations']}\\n\"\n",
    "            f\"Модель:;; {rl['Method']}\\n\\n\"\n",
    "        )\n",
    "        \n",
    "        csvfile.write(stat_header)\n",
    "        writer = csv.writer(csvfile, delimiter=';')\n",
    "        writer.writerow(fieldnames)\n",
    "        writer.writerows(arr)\n",
    "        \n",
    "        stat_footer = (\n",
    "            f\"Сумма;;{rl['H_sum']}\\n\"  \n",
    "            f\"Средний;;{rl['H_avg']}\\n\" \n",
    "            f\"Высший;;{rl['H_max']}\\n\"\n",
    "            f\"Низший;;{rl['H_min']}\\n\\n\"\n",
    "            \n",
    "            f\"σ = ;;{rl['Sigma']};;σ -;\"\n",
    "            f\"среднеквадратическое отклонение (см)\\n\" \n",
    "            \n",
    "            f\"δдоп =;;{rl['Delta_dop']};;δдоп -;\"\n",
    "            f\"допустимая погрешность прогноза (см)\\n\" \n",
    "            \n",
    "            f\"Pк =;;{rl['Pk']};;Pк -;\"\n",
    "            f\"климатическая обеспеченность в %\\n\"\n",
    "            \n",
    "            f\"Pм =;;{rl['Pm']};;Pм -;\"\n",
    "            f\"обеспеченность метода в %\\n\"\n",
    "            \n",
    "            f\"S =;;{rl['S']};;;\"\n",
    "            f\"(допустимой погрешности проверочных прогнозов)\\n\"\n",
    "            \n",
    "            f\"S/σ =;;{rl['Criterion']};;S -;\"\n",
    "            f\"среднеквадратическая погрешность (см)\\n\" \n",
    "            \n",
    "            f\"(S/σ)^2 =;;{rl['Criterion_sqr']};;S/σ -;\"\n",
    "            f\"критерий эффективности метода прогнозирования\\n\"\n",
    "            \n",
    "            f\"ρ =;;{rl['Correlation']};;ρ -;\"\n",
    "            f\"корреляционное отношение\\n\"\n",
    "            \n",
    "            f\";;;;;(оценка эффективности метода прогнозирования)\\n\"\n",
    "            f\";;;;δ50% -;погрешность (ошибка) прогнозов (см)\\n\"\n",
    "        )\n",
    "        \n",
    "        csvfile.write(stat_footer) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ae6e8e-07c7-4de1-b8cc-0ae599007b06",
   "metadata": {},
   "source": [
    "#### Запуск процесса обучения моделей, формирования наборов уравнений множественной регрессии и проверочных прогнозов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df2181-e85a-449e-bbd2-41e64908cb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_best = None\n",
    "result1 = compare_models(pr_group=1, n_test=0, norms=True, top_best=top_best)          \n",
    "result2 = compare_models(pr_group=2, n_test=0, norms=True, top_best=top_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216fe275-7bc6-4179-a1d7-a91ac0f41ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
