{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75541273-d8a0-40fe-b676-e024f18f6b41",
   "metadata": {},
   "source": [
    "#### Импорт необходимых объектов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d31a67-e1f4-4f73-b386-b54e9da7cea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from scipy.interpolate import splrep, splev\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.linear_model import Lars, LarsCV\n",
    "from sklearn.linear_model import LassoLars, LassoLarsCV\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit, OrthogonalMatchingPursuitCV\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.linear_model import TweedieRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, LassoLarsCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386c8264-7ddd-469d-9581-8eefb3f13322",
   "metadata": {},
   "source": [
    "#### Функция чтения набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cff566a-8886-47b1-a651-f3df2c864e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_river_dataset(fname, pr_list=None, y_name='H_max'):\n",
    "    pr_arr = []\n",
    "    y_arr = []\n",
    "    with open(fname, newline='') as f:\n",
    "        reader = csv.DictReader(f, delimiter=';')\n",
    "        for row in reader:\n",
    "            pr_arr_row = []\n",
    "            for pr in pr_list:\n",
    "                pr_arr_row.append(row[pr])\n",
    "\n",
    "            pr_arr.append(pr_arr_row)\n",
    "            y_arr.append(row[y_name])\n",
    "    X = np.asarray(pr_arr, dtype=np.float64)\n",
    "    y = np.asarray(y_arr, dtype=np.float64)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019a96a1-c37d-47ba-b369-2a015ec5706f",
   "metadata": {},
   "source": [
    "#### Сумма, средний, высший, низший уровни"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aa78832-4724-42e1-8e4f-8513406d88ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum(h_max):\n",
    "    return np.sum(h_max)\n",
    "    \n",
    "def get_avg(h_max):\n",
    "    return np.mean(h_max)\n",
    "    \n",
    "def get_max(h_max):\n",
    "    return np.amax(h_max)\n",
    "    \n",
    "def get_min(h_max):\n",
    "    return np.amin(h_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96dafa4-e1f7-4c26-b28d-3dfd6a2b1b14",
   "metadata": {},
   "source": [
    "#### Среднеквадратическая погрешность прогноза S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ad85fc4-c2cd-4a9f-8a0a-bb4fe4cdfe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s(h_max, h_forecast):\n",
    "    # Среднеквадратическая погрешность прогноза\n",
    "    n = h_max.shape[0]\n",
    "    sqr_diff = np.sum((h_max - h_forecast) ** 2) / (n - 1)\n",
    "    std = sqr_diff ** 0.5\n",
    "    return std    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893e98c4-4841-4b3f-b61b-284bc99af53d",
   "metadata": {},
   "source": [
    "#### Среднеквадратическое отклонение sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5079b8f9-3ae5-47a1-a6f3-214bdf69ad77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sigma(h_max):\n",
    "    # Среднеквадратическая погрешность климатическая.\n",
    "    # Рассчитывается только по всей совокупности данных.\n",
    "    return np.std(h_max, ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6ebdd8-9291-4612-9573-b5e6464fc07e",
   "metadata": {},
   "source": [
    "#### Среднее значение максимальных уровней воды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71fe5ef3-810d-40e8-87f0-9432f139319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hmax_avg(h_max):\n",
    "    # Среднее значение h_max.\n",
    "    # Рассчитывается только по всей совокупности данных.\n",
    "    return np.mean(h_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a10fa8d-d7cd-44f4-b4f2-4f652409383f",
   "metadata": {},
   "source": [
    "#### Допустимая погрешность прогноза delta_dop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22d4648d-8e14-4c63-bcf8-6a3c2cb7a829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta_dop(sigma):\n",
    "    return 0.674 * sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c1c7ff-c4e1-4639-a877-d3b78d944dea",
   "metadata": {},
   "source": [
    "#### Критерий критерий применимости и качества методики S/sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f92739a9-3b12-44bd-b51e-4ffd73e828a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_criterion(s, sigma):\n",
    "    return s / sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaec5970-ba12-4121-8403-cd13b812b2de",
   "metadata": {},
   "source": [
    "#### Климатическая обеспеченность Pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4e1b890-8fb7-4fdd-8196-610544acee2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pk(h_max, h_max_avg, delta_dop):\n",
    "    diff = np.abs(h_max - h_max_avg) / delta_dop\n",
    "    trusted_values = diff[diff <= 1.0]\n",
    "    m = trusted_values.shape[0]\n",
    "    n = h_max.shape[0]\n",
    "    return m / n * 100.00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a4c686-2946-4ea0-980a-172b2ff4dd64",
   "metadata": {},
   "source": [
    "#### Обеспеченность метода (оправдываемость) Pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68ca5adf-fbf3-49a4-8458-06d103bfacdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pm(h_max, h_forecast, delta_dop):\n",
    "    diff = np.abs(h_max - h_forecast) / delta_dop\n",
    "    trusted_values = diff[diff <= 1.0]\n",
    "    m = trusted_values.shape[0]\n",
    "    n = h_max.shape[0]\n",
    "    return m / n * 100.00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9d93f0-e243-4107-b007-cb24efbdc6f6",
   "metadata": {},
   "source": [
    "#### Корреляционное отношение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a501afb2-3736-4023-a488-a19747e54910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_ratio(criterion):\n",
    "    c_1 = (1 - criterion ** 2)\n",
    "    ro = c_1 ** 0.5 if c_1 > 0 else 0\n",
    "    return ro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c059ec96-bf22-4b2b-83f9-dc2112e0c942",
   "metadata": {},
   "source": [
    "#### Вероятная ошибка прогноза S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88e88b65-02b2-4bee-9262-b84a7a1ea70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forecast_error(s):\n",
    "    return 0.674 * s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc0abe2-cca4-4ebc-b6bf-f27c01c6b1bd",
   "metadata": {},
   "source": [
    "#### Ошибки климатического/природного прогноза для каждого года delta50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90b00b24-686d-449b-9920-aa4733a0bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta50(h_max, delta_dop, h_max_avg=None, h_max_forecast=None):\n",
    "    if h_max_forecast is None:\n",
    "        # delta50 климатическая\n",
    "        return (h_max - h_max_avg) / delta_dop\n",
    "    else:\n",
    "        # delta50 прогноза\n",
    "        return (h_max - h_max_forecast) / delta_dop\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b0cc72-ec19-437b-b6c5-8010c2e3a5bf",
   "metadata": {},
   "source": [
    "#### Функция записи списка моделей с их характеристиками в csv файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4c76ad0-d75c-4746-90dc-0d8465218463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataset_csv(dataset, dataset_name, fieldnames, pr_group):\n",
    "    with open(\n",
    "        f'results/{dataset_name}/group-{pr_group}/'\n",
    "        f'{dataset_name}-гр{pr_group}.csv', \n",
    "        'w', newline='', encoding='utf-8'\n",
    "    ) as csvfile:\n",
    "        \n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames, \n",
    "                                delimiter=';', extrasaction='ignore')\n",
    "        writer.writeheader()\n",
    "        writer.writerows(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72dc311-4aa6-4775-bd80-e4182ba30c96",
   "metadata": {},
   "source": [
    "#### Функция записи результатов экспериментов в csv файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f282d3fa-80e7-479a-94c7-c24f2d2d5b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_experiment_csv(dataset, fieldnames, filename):\n",
    "    fpath = f'results/{filename}.csv'\n",
    "    with open(fpath, 'w', newline='') as csvfile: #, encoding='cp1251'\n",
    "        \n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames, \n",
    "                                delimiter=';', extrasaction='ignore')\n",
    "        fsize = os.stat(fpath).st_size\n",
    "        if not fsize:\n",
    "            writer.writeheader()\n",
    "        writer.writerows(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b2d2a0-f9da-46e5-a0ae-45e8fe0c2482",
   "metadata": {},
   "source": [
    "#### Функция разделения набора данных на тренировочный и тестовый"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82db9e50-fadc-4c7f-9151-58c2b74df8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, n_test, shuffle=False):\n",
    "    if shuffle:\n",
    "        # Перемешивание данных\n",
    "        Xy = np.column_stack((X, y))\n",
    "        rng = np.random.default_rng(42)\n",
    "        rng.shuffle(Xy)\n",
    "        y = Xy[:, -1]\n",
    "        X = Xy[:,:-1]\n",
    "        \n",
    "    X_train = X[:-n_test]\n",
    "    y_train = y[:-n_test]\n",
    "    X_test = X[-n_test:]\n",
    "    y_test = y[-n_test:]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2719a5f9-176e-473d-8ce7-b7744d9c6e19",
   "metadata": {},
   "source": [
    "#### Функция формирования тестового набора данных с подстановкой нормированных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b464d45-843c-4792-ab02-2819edddee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_norm(x, pr_list, norms):\n",
    "    x_norm = np.copy(x)\n",
    "    for col, pr in enumerate(pr_list):\n",
    "        if pr in norms:\n",
    "            x_norm[:, col:col+1] = norms[pr]\n",
    "    return x_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c3a942-95d0-4f7f-aa39-82f61624b070",
   "metadata": {},
   "source": [
    "#### Функция получения датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7628a977-9d54-4129-928c-625b4e80d107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets():\n",
    "    datasets = {\n",
    "        #'Неман-Белица': 'Неман',\n",
    "        #'Неман-Гродно': 'Неман',\n",
    "        #'Неман-Мосты': 'Неман',\n",
    "        #'Неман-Столбцы': 'Неман',\n",
    "\n",
    "        'Вилия-Стешицы': 'Вилия',\n",
    "        'Вилия-Михалишки': 'Вилия',\n",
    "    }\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83168b0-64e2-4e58-a47b-f49f677a9eb4",
   "metadata": {},
   "source": [
    "#### Функция получения списка предикторов по названию датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bca1eea5-a699-4b0e-91fa-9fe6f4451ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictors(dataset_name, pr_group):\n",
    "\n",
    "    datasets = get_datasets()   \n",
    "    predictors_lists = {\n",
    "        'Неман': (\n",
    "            ['S_2802', 'Smax', 'H_2802', 'X', 'X1', 'X2', 'X3', 'Xs'],\n",
    "            ['Smax', 'H_2802', 'X', 'X1', 'X3'],\n",
    "            ['S_2802', 'H_2802', 'X2', 'X3', 'Xs'],\n",
    "        ),\n",
    "        'Вилия': (\n",
    "            ['S_2802', 'Smax', 'H_2802', 'X', 'X1', 'X2', 'X3', 'Xs', 'L_max', 'L_2802', 'Q12', 'Q01', 'Q02', 'Y_sum'],\n",
    "            ['Smax', 'H_2802', 'X', 'X1', 'X3', 'L_max', 'Y_sum'],\n",
    "            ['S_2802', 'H_2802', 'X2', 'X3', 'Xs', 'L_2802', 'Y_sum'],\n",
    "        )\n",
    "    }\n",
    "    return predictors_lists[datasets[dataset_name]][pr_group]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2790ff38-4843-40b6-ac40-a9efec555315",
   "metadata": {},
   "source": [
    "#### Функция получения нормированных значений предикторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a741f9dd-31c9-4ea6-a1a8-b2b684b05013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norms(dataset_name):\n",
    "    norms_list = {\n",
    "        'Неман-Белица': {'X1': 46.0, 'X2':35.0},\n",
    "        'Неман-Гродно': {'X1': 36.0, 'X2':26.0},\n",
    "        'Неман-Мосты': {'X1': 40.0, 'X2':31.0},\n",
    "        'Неман-Столбцы': {'X1': 43.0, 'X2':34.0},\n",
    "\n",
    "        'Вилия-Стешицы': {'S_max': 67.0, 'X': 112.0, 'X1': 40.0, 'X2': 33.0, 'L_max': 60.0}, # Поставить корректные значения\n",
    "        'Вилия-Михалишки': {'S_max': 60.0, 'X': 116.0, 'X1': 46.0, 'X2': 37.0, 'L_max': 57.0}, # Поставить корректные значения\n",
    "    }\n",
    "    return norms_list[dataset_name]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f83f925-d3c5-46ea-bbba-cb3cf9605113",
   "metadata": {},
   "source": [
    "#### Функция получения аугментированных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc8e198a-5d6a-4815-bbbc-94ae2d2c11d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(x_data, y_data, aug_n, aug_pow=2, s=None):\n",
    "    #print(x_data)\n",
    "    data_len = len(y_data)\n",
    "    \n",
    "    x_points = np.linspace(0, data_len, data_len)\n",
    "    \n",
    "    x_splitted = np.hsplit(x_data, x_data.shape[1])\n",
    "    #print(x_splitted)\n",
    "\n",
    "    x_list = []\n",
    "    for arr in x_splitted:\n",
    "        x_spl = splrep(x_points, arr, k=aug_pow, s=s)\n",
    "        x_points_n = np.linspace(0, data_len, aug_n)\n",
    "        x_col_augmented = splev(x_points_n, x_spl)\n",
    "        x_list.append(x_col_augmented)\n",
    "    x_augmented = np.array(x_list).T\n",
    "    #print(x_augmented)\n",
    "\n",
    "    y_points = np.linspace(0, data_len, data_len)\n",
    "    y_spl = splrep(y_points, y_data, k=aug_pow, s=s)\n",
    "    y_points_n = np.linspace(0, data_len, aug_n)\n",
    "    y_augmented = splev(y_points_n, y_spl)\n",
    "    #print(y_augmented)\n",
    "\n",
    "    plt.plot(y_points, y_data, 'o', y_points_n, y_augmented)\n",
    "    plt.plot(x_points, x_data[:, 0], 'x', x_points_n, x_augmented[:, 0])\n",
    "    plt.show()\n",
    "    \n",
    "    return x_augmented, y_augmented"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08312297-9ca3-4e7d-be60-26969a4611e7",
   "metadata": {},
   "source": [
    "#### Функция обучения и оценки моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7dff9414-8a26-4393-b480-446307aafc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(pr_group, n_test=None, norms=True, top_best=None, aug_n=0, aug_pow=2, grid_search=False, scaler=None, shuffle=True, verify=True):\n",
    "    \n",
    "    ds_dir = 'data'\n",
    "    \n",
    "    names = [\n",
    "        'LinearRegression',\n",
    "        \n",
    "        'Ridge',\n",
    "        'RidgeCV',\n",
    "        \n",
    "        'ElasticNetCV',\n",
    "        \n",
    "        'LassoCV',\n",
    "\n",
    "        'LarsCV',\n",
    "        \n",
    "        'Lars1',\n",
    "        'Lars2',\n",
    "        'Lars3',\n",
    "        'Lars4',\n",
    "        'Lars5',\n",
    "        'Lars6',\n",
    "        'Lars7',\n",
    "        # 'Lars8',\n",
    "\n",
    "        'LassoLarsCV',\n",
    "        \n",
    "        'OMPCV',\n",
    "        'OMP1',\n",
    "        'OMP2',\n",
    "        'OMP3',\n",
    "        'OMP4',\n",
    "        'OMP5',\n",
    "        'OMP6',\n",
    "        'OMP7',\n",
    "        # 'OMP8',\n",
    "        \n",
    "        'BayesianRidge',\n",
    "        'BayesianRidgeCV',\n",
    "        'ARDRegression',\n",
    "        'SGDRegressor', \n",
    "        'PassiveAggressiveRegressor',\n",
    "        # 'HuberRegressor',\n",
    "        'HuberRegressorCV',\n",
    "        'TheilSenRegressor',\n",
    "        # 'TheilSenRegressorCV',\n",
    "        'QuantileRegressor',\n",
    "        # 'QuantileRegressorCV',\n",
    "        \n",
    "        \n",
    "        # 'KNeighborsRegressor',\n",
    "        # # 'NuSVR',\n",
    "        # # 'SVR',\n",
    "        # # 'MLPRegressor',\n",
    "        \n",
    "        # # 'RandomForestRegressor',\n",
    "        # # 'ExtraTreesRegressor',\n",
    "        # # 'HistGradientBoostingRegressor',\n",
    "        # # 'BaggingRegressor',\n",
    "        # # 'VotingRegressor',\n",
    "        # # 'StackingRegressorRidge',\n",
    "        # # 'AdaBoostRegressor',\n",
    "    ]\n",
    "\n",
    "    # Инициализация генератора случайных чисел для\n",
    "    # для обеспечения воспроизводимости результатов\n",
    "    rng = np.random.RandomState(0)\n",
    "\n",
    "    # Наборы гиперпараметров моделей для алгоритма кроссвалидации\n",
    "    # Гиперпараметры для Ridge, Lasso, ElasticNet, LassoLars, HuberRegressor\n",
    "    alphas = np.logspace(-4, 3, num=100)\n",
    "    \n",
    "    # Гиперпараметры для ElasticNet\n",
    "    l1_ratio = np.linspace(0.01, 1.0, num=50)\n",
    "    \n",
    "    # Гиперпараметры для BayesianRidge\n",
    "    alphas_init = np.linspace(0.5, 2, 5)\n",
    "    lambdas_init = np.logspace(-3, 1, num=5)\n",
    "    \n",
    "    # Гиперпараметры для ARDRegression\n",
    "    alphas_lambdas = np.logspace(-7, -4, num=4)\n",
    "    \n",
    "    # Гиперпараметры для SGDRegressor\n",
    "    losses = ['squared_error', 'huber', \n",
    "              'epsilon_insensitive', 'squared_epsilon_insensitive']\n",
    "    sgd_alphas = np.logspace(-4, 1, num=100)\n",
    "   \n",
    "    # Гиперпараметры для PassiveAggressiveRegressor\n",
    "    cc = np.linspace(0.1, 1.5, 50)\n",
    "    \n",
    "    # Гиперпараметры для HuberRegressor\n",
    "    epsilons = np.append(np.linspace(1.1, 2.0, 10), [1.35])\n",
    "    \n",
    "    # Гиперпараметры для TheilSenRegressor\n",
    "    # n_subsamples = np.arange(15, 24)\n",
    "    n_subsamples = (16, 24, 32)\n",
    "    \n",
    "    # Гиперпараметры для QuantileRegressor\n",
    "    # q_alphas = np.linspace(0, 1, 5)\n",
    "    q_alphas = (0.1, 1, 2)\n",
    "           \n",
    "    \n",
    "    regressors = [\n",
    "        LinearRegression(),\n",
    "        \n",
    "        Ridge(random_state=rng) if not grid_search else \\\n",
    "        GridSearchCV(\n",
    "            estimator=Ridge(random_state=rng), \n",
    "            param_grid={\"alpha\": alphas}\n",
    "        ),\n",
    "        RidgeCV(),\n",
    "\n",
    "        ElasticNetCV(random_state=rng),\n",
    "        \n",
    "        LassoCV(max_iter=10000, n_alphas=300, random_state=0),  \n",
    "        \n",
    "        LarsCV(),\n",
    "        \n",
    "        Lars(n_nonzero_coefs=1, random_state=0),\n",
    "        Lars(n_nonzero_coefs=2, random_state=0),\n",
    "        Lars(n_nonzero_coefs=3, random_state=0),\n",
    "        Lars(n_nonzero_coefs=4, random_state=0),\n",
    "        Lars(n_nonzero_coefs=5, random_state=0),\n",
    "        Lars(n_nonzero_coefs=6, random_state=0),\n",
    "        Lars(n_nonzero_coefs=7, random_state=0),\n",
    "        # Lars(n_nonzero_coefs=8, random_state=0),\n",
    "\n",
    "        LassoLarsCV(max_iter=500, max_n_alphas=1000),\n",
    "\n",
    "        OrthogonalMatchingPursuitCV(n_jobs=-1),\n",
    "        OrthogonalMatchingPursuit(n_nonzero_coefs=1),\n",
    "        OrthogonalMatchingPursuit(n_nonzero_coefs=2),\n",
    "        OrthogonalMatchingPursuit(n_nonzero_coefs=3),\n",
    "        OrthogonalMatchingPursuit(n_nonzero_coefs=4),\n",
    "        OrthogonalMatchingPursuit(n_nonzero_coefs=5),\n",
    "        OrthogonalMatchingPursuit(n_nonzero_coefs=6),\n",
    "        OrthogonalMatchingPursuit(n_nonzero_coefs=7),\n",
    "        # OrthogonalMatchingPursuit(n_nonzero_coefs=8),\n",
    "        \n",
    "        BayesianRidge(),\n",
    "        BayesianRidge() if not grid_search else \\\n",
    "        GridSearchCV(\n",
    "            estimator=BayesianRidge(),\n",
    "            param_grid={\"alpha_init\": alphas_init, \"lambda_init\": lambdas_init}, \n",
    "            n_jobs=-1\n",
    "        ),\n",
    "\n",
    "        ARDRegression() if not grid_search else \\\n",
    "        GridSearchCV(\n",
    "            estimator=ARDRegression(), \n",
    "            param_grid={\"alpha_1\": alphas_lambdas, \"alpha_2\": alphas_lambdas,\n",
    "                        \"lambda_1\": alphas_lambdas,\"lambda_2\": alphas_lambdas}, \n",
    "            n_jobs=-1\n",
    "        ),\n",
    "\n",
    "        SGDRegressor(random_state=rng) if not grid_search else \\\n",
    "        GridSearchCV(\n",
    "            estimator=SGDRegressor(random_state=rng), \n",
    "            param_grid={\"loss\": losses, \"alpha\": sgd_alphas}, \n",
    "            n_jobs=-1\n",
    "        ),\n",
    "\n",
    "        PassiveAggressiveRegressor(random_state=rng) if not grid_search else \\\n",
    "        GridSearchCV(\n",
    "            estimator=PassiveAggressiveRegressor(random_state=rng), \n",
    "            param_grid={\"C\": cc}, \n",
    "            n_jobs=-1, \n",
    "            cv=3\n",
    "        ),\n",
    "\n",
    "        # HuberRegressor(max_iter=1000),\n",
    "        HuberRegressor(max_iter=1000) if not grid_search else \\\n",
    "        GridSearchCV(\n",
    "            estimator=HuberRegressor(), \n",
    "            param_grid={\"epsilon\": epsilons, \"alpha\": alphas}, \n",
    "            n_jobs=-1 \n",
    "        ),\n",
    "\n",
    "        TheilSenRegressor(random_state=rng, n_jobs=-1),\n",
    "        # TheilSenRegressor(random_state=rng, n_jobs=-1) if not grid_search else \\\n",
    "        # GridSearchCV(\n",
    "        #     estimator=TheilSenRegressor(random_state=rng, n_jobs=-1), \n",
    "        #     param_grid={\"n_subsamples\": n_subsamples}, \n",
    "        #     n_jobs=-1\n",
    "        # ),\n",
    "\n",
    "        QuantileRegressor(),\n",
    "        # QuantileRegressor() if not grid_search else \\\n",
    "        # GridSearchCV(\n",
    "        #     estimator=QuantileRegressor(), \n",
    "        #     param_grid={\"alpha\": q_alphas}, \n",
    "        #     n_jobs=-1\n",
    "        # ),\n",
    "        \n",
    "        \n",
    "        \n",
    "        # KNeighborsRegressor(n_neighbors=10, metric='euclidean'),\n",
    "        # NuSVR(C=5.0, nu=0.9, kernel='poly', degree=3),\n",
    "        # SVR(C=5.0, epsilon=0.2, kernel='poly', degree=3),\n",
    "        \n",
    "        \n",
    "        # MLPRegressor(\n",
    "        #     hidden_layer_sizes=(3, ), \n",
    "        #     activation='identity', \n",
    "        #     max_iter=100000, \n",
    "        #     early_stopping=True, \n",
    "        #     learning_rate='constant',\n",
    "        #     learning_rate_init=0.00025,\n",
    "        #     batch_size=75,\n",
    "        #     solver='adam',\n",
    "        #     random_state=0\n",
    "        # ),\n",
    "       \n",
    "        \n",
    "        \n",
    "        # RandomForestRegressor(n_estimators=100, criterion='absolute_error', random_state=0),\n",
    "        # ExtraTreesRegressor(n_estimators=100, criterion='squared_error', random_state=0),\n",
    "        # HistGradientBoostingRegressor(max_iter=100, loss='absolute_error', max_leaf_nodes=None, min_samples_leaf=10, random_state=0),\n",
    "        # BaggingRegressor(\n",
    "        #     #KNeighborsRegressor(n_neighbors=20, metric='euclidean'),\n",
    "        #     estimator=ExtraTreesRegressor(n_estimators=100, criterion='squared_error', random_state=0), \n",
    "        #     max_samples=0.75, max_features=0.75, n_estimators=10, random_state=0\n",
    "        # ),\n",
    "\n",
    "        # VotingRegressor(\n",
    "        #     estimators=[\n",
    "        #         ('hgbr', HistGradientBoostingRegressor(max_iter=100, loss='absolute_error', max_leaf_nodes=None, min_samples_leaf=10, random_state=0)), \n",
    "        #         ('omp', ExtraTreesRegressor(n_estimators=100, criterion='squared_error', random_state=0)), \n",
    "        #         ('knr', KNeighborsRegressor(n_neighbors=20, metric='euclidean')),\n",
    "        #         ('rfr', RandomForestRegressor(n_estimators=100, criterion='absolute_error', random_state=0)),\n",
    "        #     ]\n",
    "        # ),\n",
    "\n",
    "\n",
    "        # StackingRegressor( # RidgeCV - final estimator\n",
    "        #     estimators=[\n",
    "        #         ('knr', KNeighborsRegressor(n_neighbors=10, metric='euclidean')),\n",
    "        #         ('rfr', RandomForestRegressor(n_estimators=100, criterion='absolute_error', random_state=0)),\n",
    "        #         ('hgbr', HistGradientBoostingRegressor(max_iter=100, loss='absolute_error', max_leaf_nodes=None, min_samples_leaf=10, random_state=0)), \n",
    "        #         ('etr', ExtraTreesRegressor(n_estimators=100, criterion='squared_error', random_state=0)),\n",
    "        #         ('omp', OrthogonalMatchingPursuit(n_nonzero_coefs=5)),\n",
    "        #     ],\n",
    "        # ),\n",
    "\n",
    "        # AdaBoostRegressor(estimator=KNeighborsRegressor(n_neighbors=5, metric='euclidean'), n_estimators=100, loss='linear', random_state=0),\n",
    "        \n",
    "    ]\n",
    "\n",
    "    datasets = get_datasets()\n",
    "\n",
    "    fieldnames = [\n",
    "        'Predictors', \n",
    "        'Equations', \n",
    "        'Method', \n",
    "        'Criterion', \n",
    "        'Correlation', \n",
    "        'Pm',\n",
    "        # 'R2',\n",
    "\n",
    "        # 'Criterion_t', \n",
    "        # 'Correlation_t', \n",
    "        # 'Pm_t',\n",
    "        # 'R2_t',\n",
    "\n",
    "        # 'Group',\n",
    "        # 'Augmentation',\n",
    "        # 'Data size',\n",
    "        # 'Normalization',\n",
    "        # 'Equations',\n",
    "    ]\n",
    "\n",
    "    # Описание структуры данных переменной datasets_result\n",
    "    # datasets_result = {\n",
    "    #     \"hydropost_0\": [\n",
    "    #         { model_row }\n",
    "    #         { model_row }\n",
    "    #     ],\n",
    "    #     ...,\n",
    "    #     \"hydropost_n\": [\n",
    "    #         { model_row }\n",
    "    #         { model_row }\n",
    "    #     ],\n",
    "    # }\n",
    "    \n",
    "    \n",
    "    # Итерация по датасетам\n",
    "    datasets_result = dict()\n",
    "    for ds in datasets:\n",
    "        result_list = []\n",
    "        \n",
    "        pr_list = get_predictors(ds, pr_group)\n",
    "        \n",
    "        X, y = get_river_dataset(f'{ds_dir}/{ds}.csv', pr_list=pr_list)\n",
    "\n",
    "        # Проверочный набор данных (исходный)\n",
    "        X_prior = X.copy()\n",
    "        y_prior = y.copy()\n",
    "\n",
    "        if aug_n:\n",
    "           X_aug, y_aug = augment_data(X, y, aug_n, aug_pow=aug_pow)\n",
    "  \n",
    "        if n_test:\n",
    "            if aug_n:\n",
    "                X_train, y_train, X_test, y_test = train_test_split(X_aug, y_aug, n_test, shuffle=shuffle)\n",
    "            else:\n",
    "                X_train, y_train, X_test, y_test = train_test_split(X_prior, y_prior, n_test, shuffle=shuffle)\n",
    "        else:\n",
    "            if aug_n:\n",
    "                X_train = X_aug[:]\n",
    "                y_train = y_aug[:]\n",
    "                X_test = X[:].copy()\n",
    "                y_test = y[:].copy()\n",
    "            else:\n",
    "                X_train = X[:]\n",
    "                y_train = y[:]\n",
    "                X_test = X_train.copy()\n",
    "                y_test = y_train.copy()\n",
    "\n",
    "        # print(\"SHAPES:\")\n",
    "        # print(\"X_train.shape, y_train.shape\", X_train.shape, y_train.shape)\n",
    "        # print(\"X_test.shape, y_test.shape\", X_test.shape, y_test.shape)\n",
    "        \n",
    "        if norms:\n",
    "            norms = get_norms(ds)\n",
    "            # Подстановка норм в тестовый набор признаков\n",
    "            X_test = test_norm(X_test, pr_list, norms)\n",
    "            # Подстановка норм в исходный набор признаков\n",
    "            X_prior = test_norm(X_prior, pr_list, norms)\n",
    "            \n",
    "        # print(\"X_test:\")\n",
    "        # print(X_test)\n",
    "        # print(\"X_train:\")\n",
    "        # print(X_train)\n",
    "            \n",
    "        # Итерация по моделям регрессии\n",
    "        for name, regressor in zip(names, regressors):\n",
    "            one_model_row = dict()\n",
    "\n",
    "            print('X_train.shape', X_train.shape)\n",
    "            print('y_train.shape', y_train.shape)\n",
    "            print('X_test.shape', X_test.shape)\n",
    "            print('y_test.shape', y_test.shape)\n",
    "            n_samples = min(10000, y_train.shape[0])\n",
    "            \n",
    "            if scaler == 'standard':\n",
    "                regr = make_pipeline(StandardScaler(), regressor)\n",
    "            elif scaler == 'minmax':\n",
    "                regr = make_pipeline(MinMaxScaler(), regressor)\n",
    "            elif scaler == 'maxabs':\n",
    "                regr = make_pipeline(MaxAbsScaler(), regressor)\n",
    "            elif scaler == 'robust':\n",
    "                regr = make_pipeline(RobustScaler(), regressor)\n",
    "            elif scaler == 'uniform':\n",
    "                regr = make_pipeline(QuantileTransformer(output_distribution='uniform', n_quantiles=n_samples, random_state=0), regressor)\n",
    "            elif scaler == 'normal':\n",
    "                regr = make_pipeline(QuantileTransformer(output_distribution='normal', n_quantiles=n_samples, random_state=0), regressor)\n",
    "            elif scaler == 'normal-bc':\n",
    "                regr = make_pipeline(PowerTransformer(method='box-cox', standardize=False), regressor)\n",
    "            elif scaler == 'normal-yj':\n",
    "                regr = make_pipeline(PowerTransformer(method='yeo-johnson', standardize=False), regressor)\n",
    "            elif scaler == 'normal-bc-st':\n",
    "                regr = make_pipeline(PowerTransformer(method='box-cox', standardize=True), regressor)\n",
    "            elif scaler == 'normal-yj-st':\n",
    "                regr = make_pipeline(PowerTransformer(method='yeo-johnson', standardize=True), regressor)\n",
    "            elif scaler == 'l1norm':\n",
    "                regr = make_pipeline(Normalizer(norm='l1'), regressor)\n",
    "            elif scaler == 'l2norm':\n",
    "                regr = make_pipeline(Normalizer(norm='l2'), regressor)\n",
    "            else:\n",
    "                regr = regressor\n",
    "            \n",
    "            \n",
    "            \n",
    "            regr.fit(X_train, y_train)\n",
    "            # try:\n",
    "            #     regr.fit(X_train, y_train)\n",
    "            # except ValueError as error:\n",
    "            #     print(error)\n",
    "            #     continue\n",
    "                \n",
    "            # Прогноз по тестовому набору \n",
    "            y_predicted_test = np.ravel(regr.predict(X_test))\n",
    "            # Прогноз по исходному набору \n",
    "            y_predicted_prior = np.ravel(regr.predict(X_prior))\n",
    "\n",
    "            \n",
    "            # Очистка значений строк предикторов и уравнений перед переходом к следующей модели\n",
    "            coef = None\n",
    "            intercept = None\n",
    "            \n",
    "            try:\n",
    "                coef = regr.best_estimator_.coef_\n",
    "                intercept = regr.best_estimator_.intercept_\n",
    "                \n",
    "                if isinstance(intercept, np.ndarray):\n",
    "                    intercept = intercept[0]\n",
    "            except Exception as error:\n",
    "                                \n",
    "                try:\n",
    "                    coef = regr.coef_\n",
    "                    intercept = regr.intercept_\n",
    "                \n",
    "                    if isinstance(intercept, np.ndarray):\n",
    "                        intercept = intercept[0]\n",
    "                    print(\"ERROR1 START\")\n",
    "                    print(error)\n",
    "                    print(\"ERROR1 FINISH\")\n",
    "                except Exception as error:\n",
    "                    print(\"ERROR2 START\")\n",
    "                    print(error)\n",
    "                    print(\"ERROR2 FINISH\")\n",
    "                \n",
    "            \n",
    "            try:\n",
    "                # Коэффициенты уравнения (если есть)\n",
    "                coef = np.around(np.ravel(coef), 3)\n",
    "                intercept = round(intercept, 3)\n",
    "                \n",
    "                predictors_coef = {f: c for f, c \n",
    "                                   in zip(pr_list, coef) if c != 0.0}\n",
    "                \n",
    "                predictors = \", \".join(predictors_coef.keys())\n",
    "                \n",
    "                equation = (\n",
    "                    str(intercept) \n",
    "                    + ' ' \n",
    "                    + ' '.join(str(c) + '*' \n",
    "                               + f for f, c in predictors_coef.items())\n",
    "                )\n",
    "                \n",
    "                equation = equation.replace(\" -\", \"-\")\n",
    "                equation = equation.replace(\" \", \" + \")\n",
    "                equation = equation.replace(\"-\", \" - \")\n",
    "    \n",
    "                one_model_row['Predictors'] = predictors\n",
    "                one_model_row['Equations'] = equation\n",
    "            except Exception as error:\n",
    "                print(\"ERROR3 START\")\n",
    "                print(error)\n",
    "                print(\"ERROR3 FINISH\")\n",
    "                one_model_row['Predictors'] = \"\"\n",
    "                one_model_row['Equations'] = \"\"\n",
    "\n",
    "            # Название датасета\n",
    "            one_model_row['Dataset_name'] = ds\n",
    "\n",
    "            # Группа предикторов\n",
    "            one_model_row['Group'] = pr_group\n",
    "                \n",
    "            # Название метода\n",
    "            one_model_row['Method'] = name\n",
    "\n",
    "            # Расчет показателей качества по методике\n",
    "\n",
    "            # Сумма, максимум, минимум максимальных уровней\n",
    "            # по исходному набору:\n",
    "            one_model_row['H_sum'] = get_sum(y_prior)\n",
    "            one_model_row['H_max'] = get_max(y_prior)\n",
    "            one_model_row['H_min'] = get_min(y_prior)\n",
    "            # по тестовому набору:\n",
    "            one_model_row['H_sum_t'] = get_sum(y_test)\n",
    "            one_model_row['H_max_t'] = get_max(y_test)\n",
    "            one_model_row['H_min_t'] = get_min(y_test)\n",
    "            \n",
    "            # Среднее значение максимального уровня по всей выборке\n",
    "            # по исходному набору:\n",
    "            h_max_avg = get_hmax_avg(y_prior)\n",
    "            one_model_row['H_avg'] = h_max_avg\n",
    "            # по тестовому набору:\n",
    "            h_max_avg_t = get_hmax_avg(y_test)\n",
    "            one_model_row['H_avg_t'] = h_max_avg_t\n",
    "            \n",
    "            # Среднеквадратическое отклонение\n",
    "            # по исходному набору:\n",
    "            sigma = get_sigma(y_prior)\n",
    "            one_model_row['Sigma'] = sigma\n",
    "            # по тестовому набору:\n",
    "            sigma_t = get_sigma(y_test)\n",
    "            one_model_row['Sigma_t'] = sigma_t\n",
    "            \n",
    "            # Допустимая погрешность прогноза\n",
    "            # по исходному набору:\n",
    "            delta_dop = get_delta_dop(sigma)\n",
    "            one_model_row['Delta_dop'] = delta_dop\n",
    "            # по тестовому набору:\n",
    "            delta_dop_t = get_delta_dop(sigma_t)\n",
    "            one_model_row['Delta_dop_t'] = delta_dop_t\n",
    "            \n",
    "            # Обеспеченность климатическая Pk \n",
    "            # по исходному набору:\n",
    "            pk = get_pk(y_prior, h_max_avg, delta_dop)\n",
    "            one_model_row['Pk'] = pk\n",
    "            # по тестовому набору:\n",
    "            pk_t = get_pk(y_test, h_max_avg_t, delta_dop_t)\n",
    "            one_model_row['Pk_t'] = pk_t\n",
    "\n",
    "            # Обеспеченность метода (оправдываемость) Pm\n",
    "            # по исходному набору:\n",
    "            pm = get_pm(y_prior, y_predicted_prior, delta_dop)\n",
    "            one_model_row['Pm'] = pm\n",
    "            # по тестовому набору:\n",
    "            pm_t = get_pm(y_test, y_predicted_test, delta_dop_t)\n",
    "            one_model_row['Pm_t'] = pm_t\n",
    "\n",
    "            # Среднеквадратическая погрешность прогноза\n",
    "            # по исходному набору:\n",
    "            s_forecast = get_s(y_prior, y_predicted_prior)\n",
    "            one_model_row['S'] = s_forecast\n",
    "            # по тестовому набору:\n",
    "            s_forecast_t = get_s(y_test, y_predicted_test)\n",
    "            one_model_row['S_t'] = s_forecast_t\n",
    "            \n",
    "            # Критерий эффективности метода прогнозирования \n",
    "            # климатический S/sigma\n",
    "            # по исходному набору:\n",
    "            criterion_forecast = get_criterion(s_forecast, sigma)\n",
    "            one_model_row['Criterion'] = criterion_forecast\n",
    "            # по тестовому набору:\n",
    "            criterion_forecast_t = get_criterion(s_forecast_t, sigma_t)\n",
    "            one_model_row['Criterion_t'] = criterion_forecast_t\n",
    "            \n",
    "            # Критерий эффективности метода прогнозирования \n",
    "            # климатический S/sigma в квадрате\n",
    "            # по исходному набору:\n",
    "            criterion_sqr = get_criterion(s_forecast, sigma) ** 2.0\n",
    "            one_model_row['Criterion_sqr'] = criterion_sqr\n",
    "            # по тестовому набору:\n",
    "            criterion_sqr_t = get_criterion(s_forecast_t, sigma_t) ** 2.0\n",
    "            one_model_row['Criterion_sqr_t'] = criterion_sqr_t\n",
    "\n",
    "            \n",
    "            # Корреляционное отношение ro\n",
    "            # по исходному набору:\n",
    "            correlation_forecast = get_correlation_ratio(criterion_forecast)\n",
    "            one_model_row['Correlation'] = correlation_forecast\n",
    "            # по тестовому набору:\n",
    "            correlation_forecast_t = get_correlation_ratio(criterion_forecast_t)\n",
    "            one_model_row['Correlation_t'] = correlation_forecast_t\n",
    "            \n",
    "            # Коэффициент детерминации R2\n",
    "            # по исходному набору:\n",
    "            one_model_row['R2'] = regr.score(X_prior, y_prior)\n",
    "            # по тестовому набору:\n",
    "            one_model_row['R2_t'] = regr.score(X_test, y_test)\n",
    "\n",
    "            \n",
    "            # Обученная модель\n",
    "            one_model_row['Model'] = regr\n",
    "\n",
    "            # Дополнительные поля для сравнения результатов экспериментов\n",
    "            one_model_row['Group'] = pr_group\n",
    "            one_model_row['Augmentation'] = f'Spline {aug_pow}' if aug_n > 0 else ''\n",
    "            one_model_row['Data size'] = X_train.shape[0]\n",
    "            one_model_row['Normalization'] = scaler\n",
    "            one_model_row['Equation'] = 'Yes' if one_model_row['Equations'] else ''\n",
    "            one_model_row['Shuffle'] = 'Yes' if shuffle else ''\n",
    "            \n",
    "            # Добавление результатов модели в результирующий список по датасету\n",
    "            result_list.append(one_model_row)\n",
    "            \n",
    "\n",
    "        # Сортировка результатов по каждому датасету\n",
    "        result_list.sort(\n",
    "            key=lambda row: (row['Criterion'], \n",
    "                             -row['Correlation'], \n",
    "                             -row['Pm'])\n",
    "        )\n",
    "\n",
    "        datasets_result[ds] = result_list\n",
    "\n",
    "        # Запись в .csv файл\n",
    "        write_dataset_csv(result_list, ds, fieldnames, pr_group=pr_group)\n",
    "\n",
    "        # Формирование проверочных прогнозов по исходным данным\n",
    "        if verify:\n",
    "            for i, rl in enumerate(result_list):\n",
    "                if top_best is not None:\n",
    "                    if i >= top_best:\n",
    "                        break\n",
    "                verify_forecast(ds, rl, i, pr_group=pr_group, n_test=n_test, norms=norms)\n",
    "\n",
    "    return datasets_result"
   ]
  },
  {
   "cell_type": "raw",
   "id": "62ef4a5d-540a-417d-9ef9-9b37afd6dfd7",
   "metadata": {},
   "source": [
    "Поля в таблице сравнения:\n",
    "\n",
    "Группа предикторов (название группы)\n",
    "Расширение данных (вид расширения -линейная, нелинейная интерпол)\n",
    "Размер данных (количество точек)\n",
    "!Нелинейное преобразование входных данных (степень полинома)\n",
    "Нормализация данных (вид нормализации)\n",
    "Уравнение\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1d848a-fd25-4827-989d-013f2e6d1fbd",
   "metadata": {},
   "source": [
    "#### Функция формирования проверочных прогнозов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7d9ced3-0d12-460b-8cd3-6b030f713b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_forecast(dataset_name, rl, num, pr_group, n_test=None, norms=True):\n",
    "\n",
    "    ds_dir = 'data'\n",
    "\n",
    "    pr_list = get_predictors(dataset_name, pr_group)\n",
    "    pr_list = ['year'] + pr_list\n",
    "    \n",
    "    fieldnames = [\n",
    "        '№', \n",
    "        'Год',\n",
    "        'Hmax фактический', \n",
    "        'Hф-Hср', \n",
    "        '(Hф-Hср)^2', \n",
    "        \n",
    "        'δ50% Погрешность климатических прогнозов '\n",
    "        'в долях от допустимой погрешности',\n",
    "        \n",
    "        'Hmax прогнозный', \n",
    "        'Hф-Hп', \n",
    "        '(Hф-Hп)^2', \n",
    "        \n",
    "        'δ50% Погрешность проверочных прогнозов '\n",
    "        'в долях от допустимой погрешности',\n",
    "    ]\n",
    "\n",
    "    X, y = get_river_dataset(\n",
    "        f'{ds_dir}/{dataset_name}.csv', pr_list=pr_list, y_name='H_max'\n",
    "    )\n",
    "\n",
    "    if n_test:\n",
    "        _, _, X_test, y_test = train_test_split(X, y, n_test, shuffle=False)\n",
    "    else:\n",
    "        X_test = X.copy()\n",
    "        y_test = y.copy()\n",
    "\n",
    "    if norms:\n",
    "        norms = get_norms(dataset_name)\n",
    "        X_test = test_norm(X_test, pr_list, norms)\n",
    "\n",
    "    # Выделение первой колонки (года) из набора предикторов\n",
    "    years = X_test[:, 0].copy()\n",
    "    X_test = X_test[:, 1:].copy()\n",
    "    \n",
    "    # Forecast\n",
    "    h_max_forecast = np.ravel(rl['Model'].predict(X_test))\n",
    "    \n",
    "    # Hсредний\n",
    "    h_max_avg = np.mean(y)\n",
    "\n",
    "    # H - Hсредний\n",
    "    diff_fact = y_test - h_max_avg\n",
    "\n",
    "    # (H - Hсредний) в квадрате\n",
    "    diff_fact_sqr = diff_fact ** 2\n",
    "\n",
    "    # Погрешность климатических прогнозов в долях от допустимой погрешности\n",
    "    delta_dop = get_delta_dop(get_sigma(y))\n",
    "    error_climate = get_delta50(y_test, delta_dop, h_max_avg=h_max_avg)\n",
    "\n",
    "    # H - Hпрогнозный\n",
    "    diff_forecast = y_test - h_max_forecast\n",
    "\n",
    "    # (H - Hпрогнозный) в квадрате\n",
    "    diff_forecast_sqr = diff_forecast ** 2       \n",
    "\n",
    "    # Погрешность проверочных прогнозов в долях от допустимой погрешности\n",
    "    error_forecast = get_delta50(\n",
    "        y_test, delta_dop, h_max_forecast=h_max_forecast\n",
    "    )\n",
    "\n",
    "    # Номер по порядку\n",
    "    rows_num = y_test.shape[0]\n",
    "    npp = np.arange(1, rows_num + 1, 1)\n",
    "\n",
    "    # Конкатенация массивов\n",
    "    att_tuple = (\n",
    "        npp, \n",
    "        years, \n",
    "        y_test, \n",
    "        diff_fact, \n",
    "        diff_fact_sqr, \n",
    "        error_climate, \n",
    "        h_max_forecast, \n",
    "        diff_forecast, \n",
    "        diff_forecast_sqr, \n",
    "        error_forecast\n",
    "    )\n",
    "    \n",
    "    arr = np.column_stack(att_tuple)\n",
    "    arr = arr.tolist()\n",
    "\n",
    "    # Обеспеченность метода (оправдываемость) Pm\n",
    "    pm = get_pm(y_test, h_max_forecast, delta_dop)\n",
    "    \n",
    "    # Запись проверочного прогноза в csv файл\n",
    "    with open(\n",
    "        f'results/{dataset_name}/group-{pr_group}/{dataset_name}'\n",
    "        f'-проверочный-гр{pr_group}-{num:0>2}.csv', \n",
    "        'w', \n",
    "        newline='', \n",
    "        encoding='utf-8'\n",
    "    ) as csvfile:\n",
    "        \n",
    "        stat_header = (\n",
    "            f\"Таблица  - \"\n",
    "            f\"Проверочные прогнозы максимумов весеннего половодья\\n\"\n",
    "            f\"р.{rl['Dataset_name']}\\n\"\n",
    "            f\"Предикторы:;; {rl['Predictors']}\\n\"\n",
    "            f\"Уравнение:;; {rl['Equations']}\\n\"\n",
    "            f\"Модель:;; {rl['Method']}\\n\\n\"\n",
    "        )\n",
    "        \n",
    "        csvfile.write(stat_header)\n",
    "        writer = csv.writer(csvfile, delimiter=';')\n",
    "        writer.writerow(fieldnames)\n",
    "        writer.writerows(arr)\n",
    "        \n",
    "        stat_footer = (\n",
    "            f\"Сумма;;{rl['H_sum']}\\n\"  \n",
    "            f\"Средний;;{rl['H_avg']}\\n\" \n",
    "            f\"Высший;;{rl['H_max']}\\n\"\n",
    "            f\"Низший;;{rl['H_min']}\\n\\n\"\n",
    "            \n",
    "            f\"σ = ;;{rl['Sigma']};;σ -;\"\n",
    "            f\"среднеквадратическое отклонение (см)\\n\" \n",
    "            \n",
    "            f\"δдоп =;;{rl['Delta_dop']};;δдоп -;\"\n",
    "            f\"допустимая погрешность прогноза (см)\\n\" \n",
    "            \n",
    "            f\"Pк =;;{rl['Pk']};;Pк -;\"\n",
    "            f\"климатическая обеспеченность в %\\n\"\n",
    "            \n",
    "            f\"Pм =;;{rl['Pm']};;Pм -;\"\n",
    "            f\"обеспеченность метода в %\\n\"\n",
    "            \n",
    "            f\"S =;;{rl['S']};;;\"\n",
    "            f\"(допустимой погрешности проверочных прогнозов)\\n\"\n",
    "            \n",
    "            f\"S/σ =;;{rl['Criterion']};;S -;\"\n",
    "            f\"среднеквадратическая погрешность (см)\\n\" \n",
    "            \n",
    "            f\"(S/σ)^2 =;;{rl['Criterion_sqr']};;S/σ -;\"\n",
    "            f\"критерий эффективности метода прогнозирования\\n\"\n",
    "            \n",
    "            f\"ρ =;;{rl['Correlation']};;ρ -;\"\n",
    "            f\"корреляционное отношение\\n\"\n",
    "            \n",
    "            f\";;;;;(оценка эффективности метода прогнозирования)\\n\"\n",
    "            f\";;;;δ50% -;погрешность (ошибка) прогнозов (см)\\n\"\n",
    "        )\n",
    "        \n",
    "        csvfile.write(stat_footer) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ae6e8e-07c7-4de1-b8cc-0ae599007b06",
   "metadata": {},
   "source": [
    "#### Запуск процесса обучения моделей, формирования наборов уравнений множественной регрессии и проверочных прогнозов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48df2181-e85a-449e-bbd2-41e64908cb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'LinearRegression' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'RidgeCV' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'ElasticNetCV' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'LassoCV' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'LarsCV' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'LassoLarsCV' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuitCV' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'BayesianRidge' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'TheilSenRegressor' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'QuantileRegressor' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'LinearRegression' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ruslan\\projects\\pkogo\\env_ogo\\lib\\site-packages\\sklearn\\linear_model\\_quantile.py:186: FutureWarning: The default solver will change from 'interior-point' to 'highs' in version 1.4. Set `solver='highs'` or to the desired solver to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'RidgeCV' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'ElasticNetCV' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'LassoCV' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'LarsCV' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'LassoLarsCV' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuitCV' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'BayesianRidge' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ruslan\\projects\\pkogo\\env_ogo\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'TheilSenRegressor' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'QuantileRegressor' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'LinearRegression' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ruslan\\projects\\pkogo\\env_ogo\\lib\\site-packages\\sklearn\\linear_model\\_quantile.py:186: FutureWarning: The default solver will change from 'interior-point' to 'highs' in version 1.4. Set `solver='highs'` or to the desired solver to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'RidgeCV' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'ElasticNetCV' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'LassoCV' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'LarsCV' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'LassoLarsCV' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuitCV' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'BayesianRidge' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ruslan\\projects\\pkogo\\env_ogo\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'TheilSenRegressor' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'QuantileRegressor' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'LinearRegression' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ruslan\\projects\\pkogo\\env_ogo\\lib\\site-packages\\sklearn\\linear_model\\_quantile.py:186: FutureWarning: The default solver will change from 'interior-point' to 'highs' in version 1.4. Set `solver='highs'` or to the desired solver to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'RidgeCV' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'ElasticNetCV' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'LassoCV' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'LarsCV' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'Lars' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'LassoLarsCV' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuitCV' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'OrthogonalMatchingPursuit' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'BayesianRidge' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ruslan\\projects\\pkogo\\env_ogo\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'TheilSenRegressor' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n",
      "X_train.shape (30, 7)\n",
      "y_train.shape (30,)\n",
      "X_test.shape (30, 7)\n",
      "y_test.shape (30,)\n",
      "ERROR1 START\n",
      "'QuantileRegressor' object has no attribute 'best_estimator_'\n",
      "ERROR1 FINISH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ruslan\\projects\\pkogo\\env_ogo\\lib\\site-packages\\sklearn\\linear_model\\_quantile.py:186: FutureWarning: The default solver will change from 'interior-point' to 'highs' in version 1.4. Set `solver='highs'` or to the desired solver to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "top_best = None\n",
    "\n",
    "exp_fieldnames = [\n",
    "        'Dataset_name',\n",
    "        'Group',\n",
    "        'Method',\n",
    "        'Criterion',\n",
    "        'Correlation',\n",
    "        'Pm',\n",
    "        'R2',\n",
    "    \n",
    "        \n",
    "        'Augmentation',\n",
    "        'Data size',\n",
    "        'Normalization',\n",
    "        'Shuffle',\n",
    "        'Equation',\n",
    "        'Predictors',\n",
    "    ]\n",
    "\n",
    "experiments = [\n",
    "\n",
    "    #compare_models(pr_group=0, n_test=200, norms=True, top_best=top_best, aug_n=1200, aug_pow=2, grid_search=True, scaler='None', shuffle=True, verify=False),\n",
    "    #compare_models(pr_group=0, n_test=200, norms=True, top_best=top_best, aug_n=1200, aug_pow=2, grid_search=True, scaler='None', shuffle=False, verify=False),\n",
    "    compare_models(pr_group=1, n_test=0, norms=True, top_best=top_best, aug_n=0, aug_pow=0, grid_search=True, scaler='None', shuffle=True, verify=True),\n",
    "    compare_models(pr_group=2, n_test=0, norms=True, top_best=top_best, aug_n=0, aug_pow=0, grid_search=True, scaler='None', shuffle=True, verify=True),\n",
    "    #compare_models(pr_group=0, n_test=0, norms=True, top_best=top_best, aug_n=0, aug_pow=0, grid_search=True, scaler='None', shuffle=False, verify=False),\n",
    "    # compare_models(pr_group=0, n_test=70, norms=True, top_best=top_best, aug_n=770, aug_pow=1, grid_search=True, scaler='none', verify_forecast=False),\n",
    "    # compare_models(pr_group=0, n_test=150, norms=True, top_best=top_best, aug_n=1650, aug_pow=1, grid_search=True, scaler='none', verify_forecast=False),\n",
    "    # compare_models(pr_group=0, n_test=100, norms=True, top_best=top_best, aug_n=1000, aug_pow=2, grid_search=True, scaler='none', verify_forecast=False),\n",
    "    # compare_models(pr_group=0, n_test=100, norms=True, top_best=top_best, aug_n=1000, aug_pow=3, grid_search=True, scaler='none', verify_forecast=False),\n",
    "    # compare_models(pr_group=0, n_test=100, norms=True, top_best=top_best, aug_n=1000, aug_pow=4, grid_search=True, scaler='none', verify_forecast=False),\n",
    "]\n",
    "\n",
    "exp_results = []\n",
    "for ds in experiments:\n",
    "    #print(ds)\n",
    "    for k, v in ds.items():\n",
    "        exp_results.extend(v)\n",
    "        \n",
    "exp_results.sort(\n",
    "    key=lambda row: (row['Dataset_name'], -row['R2'])\n",
    ")\n",
    "write_experiment_csv(exp_results, exp_fieldnames, 'experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216fe275-7bc6-4179-a1d7-a91ac0f41ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed07e2f3-c904-4be0-9a46-09c0617615ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  3]\n",
      " [ 5  7]\n",
      " [-1 -2]\n",
      " [-3 -4]]\n",
      "[[2]\n",
      " [4]\n",
      " [6]\n",
      " [8]]\n",
      "[[ 1  3  2]\n",
      " [ 5  7  4]\n",
      " [-1 -2  6]\n",
      " [-3 -4  8]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,3],[5,7],\n",
    "    [-1,-2],[-3,-4]])\n",
    "b = np.array([2,4,6,8])[:, np.newaxis]\n",
    "print(a)\n",
    "print(b)\n",
    "arr = np.column_stack((a,b))\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64669556-d315-4a9c-950c-a03ee9174b69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
